# Scallop, Viara, and the Neuro-Symbolic Path to Smarter AI

**Published:** March 23, 2025  
**Duration:** 17m 12s  
**Episode ID:** 17693214

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17693214-scallop-viara-and-the-neuro-symbolic-path-to-smarter-ai)**

## Description

We dive into Scallop, a Datalog-based declarative language that acts as a scalable symbolic reasoning engine, capable of discrete, probabilistic, and differentiable reasoning, and how it integrates with PyTorch workflows. We unpack Viara, which adds probabilistic relational reasoning for foundation models (GPT, CLIP, SAM), using foreign predicates and foreign attributes to call external models. Tune in for practical patterns like semantic parsing and structured text extraction, and a discussion on why neuro-symbolic AI could unlock deeper understanding and generalization.

## Transcript

Welcome back to the deep dive, everybody. Today we're going deep on how to make AI smarter, like actually reason better. And we're focusing on this system called Scallop. Pretty interesting tech, really pushing the boundaries of software engineering and AI as we know it. Yeah, definitely. Neural networks are amazing, right? Image recognition, natural language processing, all that. But when it comes to like abstract reasoning, they kind of fall short. So Scallop is trying to solve that, bringing together the strengths of those neural networks with the more structured, logical, symbolic AI side of things. Really, the idea is to like get rid of the weaknesses by, you know, combining them, kind of like Voltron. Right, exactly. So today we're going to break down Scallop, like what it is, how it actually works, the computer science behind it, and then like what it can do for making AI smarter across the board. We've got some cool new research we're diving into, should paint a pretty clear picture. So first things first, what is Scallop, like fundamentally from a CS perspective? Well, at its core, Scallop is a declarative programming language. And it's based on Datalog, which for computer science folks out there, you know, it's a logic-based query language. Really powerful for relational data. So that's like the foundation, these logical rules, a big part of what symbolic AI is all about. Interesting. So not reinventing the wheel, but using like solid, established CS principles. So then what does Scallop like actually do? What's its main function as a software, you know, tool? It's a Datalog solver, a really scalable one. But the cool part, especially for AI these days, is that it can handle like different types of reasoning, discrete reasoning, probabilistic reasoning, even differentiable reasoning. Think of those as like different ways to get to an answer computationally, and Scallop can, you know, switch between them depending on what the AI task needs. So not a one-trick pony, lots of options there. Now when it comes to actually using Scallop, how does it fit into the software ecosystem? Does it play nice with other tools and libraries, or is it more standalone? Integration is really key to how it was designed. Scallop has these things called bindings, right? And basically what they do is let it act like a logic reasoning module right inside your Python code. For software engineers, machine learning folks, that's huge. It means you can integrate it directly into your existing ML workflows, especially if you're using PyTorch, which let's face it, tons of people are. Yeah, that tight integration with PyTorch could really change the game building those more, you know, advanced AI systems. So let's zoom out for a second and talk about this whole neural and symbolic AI thing. For someone who might know, like, one way better than the other, what's the main idea behind this neuro-symbolic approach, and where does Scallop fit in, like, architecturally? Sure, so neuro-symbolic AI. It's basically trying to take the best of both worlds, right? Two areas of computer science that have kind of separate for a while. Neural networks, they're the champs at pattern recognition, learning all those complex relationships straight from the data. But symbolic AI, on the other hand, is all about representing knowledge in a structured, logical way, doing that rule-based reasoning. So think of it like this. Neural networks can learn to recognize a cat in a picture, but symbolic AI can define what a cat is, how it relates to other animals, that kind of thing. Yeah, okay, that's a good way to put it. So each has its own, like, superpowers and kryptonite, right, when it comes to tough AI problems. Exactly. And the argument, you know, big names like Leslie Valiant, Gary Marcus, they've been saying, for AI to get to, like, human-level intelligence, really reason, understand cause and effect, generalize beyond just the data it's trained on, we got to bridge this gap. Symbolic AI gives you that framework for abstract knowledge, logical manipulations, neural networks, they struggle with that. Makes sense. So how does Scallop, as a piece of software, actually enable this combination? How does it all work? It's the symbolic reasoning engine, basically. It can talk to those neural components. Developers can, you know, write out these logical rules and then connect them to the output or even the internal workings of neural networks. And to make things even smoother, researchers built more specialized frameworks on top of Scallop to make that integration super sleek. One of the best examples is Viara. Viara, okay. Tell me more. How does it build on Scallop? So Viara, it takes Scallop and adds this probabilistic relational approach. It's really designed for those big foundation models we hear about all the time. The cool part, from a CS perspective, is how it treats those models, you know, like GPT for language, CLIP for image text, SAM for image segmentation. It treats them like stateless functions, basically. They take in structured relational data and spit out, you know, more structured relational data. So instead of just throwing raw text or images at these huge models, Viara lets you interact with them in this more structured way using Scallop's relational logic. Bingo. And because Viara is built right on Scallop, it's super natural to combine these cutting-edge foundation models with good old-fashioned logic programs. Huge potential there. Way more sophisticated AI applications, you know, reasoning across all sorts of data types. That's a game changer for sure. So let's get into the nitty-gritty. How does Scallop and Viara, by extension, actually talk to these foundation models? From a software engineering point of view, what's going on under the hood? One of the core things is this relational programming, right? It can actually call out to the foundation models. There are two main tools for that. Foreign predicates and foreign attributes. Foreign predicates, foreign attributes. Okay, break it down for me. What are foreign predicates exactly? Okay, so think of them like special functions you can use within Scallop's logic rules. Regular predicates work on data that's already in Scallop's knowledge base, right? But foreign predicates, they can reach outside, call these external functions, like talk to a language model's API. The key is they take some arguments that Scallop already knows. Those are the bounded arguments. And then based on what that external function says, they return new info, the free arguments. And to make things run faster, there's this memization thing built in. It's a classic CS trick. It basically stores the results of those expensive function calls. So if it sees the same inputs again, boom, it reuses them, saves a ton of time. Love me some optimization. That memization is super practical, especially for real-world stuff. What about those foreign attributes then? How do they work? So foreign attributes are basically like higher-order functions. You use them to decorate the predicates you declare, like adding a little note. This lets you configure things, abstract away some of the messy details of talking to those external models. Like VIRA, it has this add GPT attribute. You slap that on a predicate, you're basically telling Scallop, hey, this guy's going to be using GPT for text generation or completion. The arguments you give to add GPT can specify things like the prompt template you want or even some example inputs and outputs to guide the model, kind of like few-shot learning in ML. Ah, so the add GPT attribute is like a nice little wrapper, makes it easier for software engineers to use GPT within their Scallop kind, hides all that API call stuff and data formatting, right? Exactly, raises the level of abstraction. Much easier to work with these powerful models when you're writing logic-based programs. Now, let's see some real-world examples. How Scallop, especially with VIRA, actually uses these different foundation models. Let's start with the language models, all those text-based tasks. Yeah, we saw that add GPT attribute before. How would that actually be used, like in a real program? Okay, so you could use it to make a predicate that pulls out specific information from some text. Say you define a rule like population, location.population, and you decorate that population predicate with add GPT, right? Give it a prompt template that's like, what is the population of location? Now, whenever your Scallop program needs to find the population of, I don't know, London, it'll use GPT to try and answer that based on the prompt. You can also just use basic foreign predicates to have GPT do more open-ended text generation based on whatever logic your Scallop program is working with. Okay, that's really cool, a structured way to get info from all that messy text data. What about tasks where you gotta understand the meaning of the text, like semantic parsing? VIRA has you covered there. It's got attributes like add gsemantic parse specifically for that. You basically define domain-specific language, or DSL, which is like a formal, structured way to represent the meaning of natural language within a specific context. Then you use that add gsemantic parse attribute to have a language model translate regular language queries into your fancy DSL expressions. So someone could ask a question in plain English, and the system uses GPT to turn that into a precise, machine-readable query, something your program can actually work with. Nice bridge between how humans talk and how computers think. What other text stuff can Scallop handle? It's also really good at pulling out relational data from text. You've got the at gtexttract relation attribute lets you tell language models to find and extract facts, usually in the form of those subject-predicate-object

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
