# HealthBench: Measuring Safe, Real-World AI in Healthcare

**Published:** May 13, 2025  
**Duration:** 15m 30s  
**Episode ID:** 17692510

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692510-healthbench-measuring-safe-real-world-ai-in-healthcare)**

## Description

An in-depth look at HealthBench, the open-source benchmark for safe, effective healthcare AI. We explore how 5,000 multi-turn clinical chats are scored by 262 physicians across 60 countries on 48,562 criteria, covering accuracy, communication, context, and instruction following. We also review early results (GPT-3.5 Turbo ~16%, GPT-4 ~32%, O3 ~60%, and the surprising Nano outperforming a larger model) and why ecological validity matters for real-world medical AI.

## Transcript

Welcome back to Science Corner, our regular segment for anyone who loves digging into new research. Glad to be here. Today we're unpacking something really fascinating at the crossroads of AI and healthcare. It's called HealthBench. Yes, and it's a genuinely critical area. I mean, the potential for these large language models, LLMs, to change healthcare is just immense. Absolutely. Things like getting information out there, supporting doctors and nurses. Exactly, expanding access, helping clinicians. The possibilities keep growing. But, you know, with that potential comes a huge responsibility, right? How do we make sure these AI systems are actually safe and effective? We need solid ways to test them. And that leads us right to HealthBench. It's a new benchmark, it's open source, and it's specifically built to measure how these LLMs perform and crucially, how safe they are in healthcare situations. Okay, HealthBench. Sounds important. Can you give us a bit more detail? What does it actually involve? What's being measured? So, at its core, HealthBench looks at about 5,000 multi-turn conversations. Multi-turn? So like a real back and forth? Precisely. Think of it as a simulated chat between the AI and a user. Maybe a patient asking questions, maybe a doctor using it as an assistant. It goes way beyond just simple Q&A. That makes sense. Real medical interactions are rarely just one question, one answer. There's follow-up, clarification. Exactly. And the way it's evaluated is also quite unique. It doesn't just use standard AI scores. HealthBench uses these detailed rubrics. Rubrics, like scoring guides. Yes, comprehensive scoring guides. And the really important part is that they were created by physicians, a lot of physicians. Ah, okay. So grounded in actual medical expertise. How many doctors were involved in this? It was quite a large group, 262 physicians, actually. Wow. And they came from 26 different specialties across 60 countries. So a really diverse global perspective. That's impressive. That diversity must make the benchmark much stronger, more applicable everywhere. Definitely. And these rubrics they created, they're incredibly detailed. For those 5,000 conversations, there are, get this, 48,562 unique criteria. 48,000. That's a lot of criteria. What kinds of things are they looking for? Well, obviously clinical accuracy is huge. Is the medical information correct? But it's much broader than that. Okay. They look at completeness. You know, did the AI give a full answer? Communication quality was clear, empathetic, appropriate for who it was talking to. Also context understanding. Did it grasp the situation? Yeah. And instruction following, which is vital if a clinician is trying to use it for, say, summarizing notes. Right. So it's not just what it says, but how it says it and if it understands the whole interaction. That sounds incredibly thorough. It really is. So for our deep dive today, what's our main goal? What should we and you listening hope to understand by the end? Good question. I think our mission is threefold. First, really get how HealthBench works, what makes it different. Second, look at what it's already telling us about today's LLMs in healthcare. Okay. And third, maybe most importantly, understand why this kind of benchmark matters so much for the future, for making sure AI in medicine moves forward safely and beneficially. Got it. So recap. HealthBench uses realistic back and forth conversations, judged by hundreds of doctors using super detailed criteria covering accuracy, communication, context, the works, all to get a real handle on AI safety and effectiveness in medicine. You've got it. And as we dig deeper, I think you'll see why this level of detail gives us much more meaningful insights than older methods. All right, let's dig in then. What are some of those core design principles that really set HealthBench apart? Well, as we touched on, that focus on multi-turn realistic dialogues is probably the biggest one. Right. It's a huge step up from benchmarks that just use, say, multiple choice questions or single shot answers. Those just don't reflect how healthcare conversations actually flow. Yeah, that makes total sense. You need to see how the AI handles clarification, asking follow-up questions, remembering earlier parts of the chat. Exactly. Capturing those nuances is key. And the other critical piece, of course, are those physician-authored rubrics. Scoring guides made by doctors. Yes. These aren't generic AI scores. They are tailor-made by medical experts for each specific conversation, focusing on what makes a response helpful and, crucially, safe in that context. And you mentioned these rubrics cover more than just factual accuracy, these behavioral dimensions. Absolutely. So under clinical accuracy, they check diagnoses, treatment info, things like that. Right. But then communication quality looks at clarity, tone, empathy, suitability for the user. Okay. Context awareness checks if the AI understands the patient's situation. And instruction following assesses if it does what it's asked, especially by a professional. It's a truly holistic view then, not just the medical facts, but the whole interaction. Exactly right. And by looking at performance across different scenarios, maybe an emergency situation versus a health query and across all these dimensions, HealthBench paints a very detailed picture of where a model shines and where it still struggles. That level of detail must be gold for the people actually building these AI models. It really is. It's less of a final grade and more of a diagnostic tool. It can pinpoint specific weaknesses. Maybe a model is great on knowledge recall, but terrible at asking clarifying questions when it doesn't have enough information. HealthBench can show that. Okay, so it's a powerful diagnostic. What has it actually shown us so far? What are the results telling us about current LLMs? You mentioned some numbers earlier. Yes. The progress, just looking at the scores on HealthBench over the last couple of years is pretty remarkable. How so? Well, early models like GPT-3.5 Turbo were scoring around, say, 16% on this benchmark. Okay, not very high. No. Then you look at newer ones. GPT-4.0 hit 32%. And a very recent model, it's called O3 in the paper, reached 60%. 60%? That's a huge jump from 16%. What does 60% mean in this context? It suggests a decent level of proficiency across a wider range of these healthcare tasks. But importantly, it also shows there's still quite a way to go to reach, say, true expert-level performance consistently. Plenty of room for improvement. Still, that increase from 16% to 60% in what sounds like a fairly short time, that's fast. It is. The pace of improvement itself is noteworthy. These models are getting better and faster at handling these complex healthcare dialogues. Were there any other maybe surprising findings? I think you mentioned smaller models. Ah, yes, that was quite interesting. A model called GPT-4.1 Nano, which is designed to be much smaller and more efficient. Nano, okay. It actually outperformed the much larger GPT-4.0 on HealthBench. Really? The smaller one did better. Yes. And this Nano model uses something like 25 times less computing power for each interaction. Wow. So bigger isn't always better. It suggests that, definitely. It implies that progress isn't just about throwing more data and more computing power at the problem. Innovations in the actual model design, the training techniques, they matter hugely. And that has big implications, right? Yeah. For cost, for making these tools accessible. Absolutely. If smaller, cheaper models can perform this well, it opens doors for using them in places with fewer resources. Where running massive models just isn't feasible. It's a very encouraging sign for equitable deployment. Yeah, that is encouraging. It shows how benchmarks like HealthBench can guide development towards practical, real-world solutions. Precisely. So we've established HealthBench is more detailed, more realistic. Why is this move away from older methods like multiple-choice tests so important for AI in medicine? Fundamentally, it's about trust and relevance. Older methods, like those medical knowledge exams, while they can be useful, but they're also easier to game. An AI might memorize facts to ace a test. Right, but that doesn't mean it can actually talk to a patient helpfully or safely. Exactly. Those tests don't capture the ability to engage in a meaningful dialogue, to ask the right follow-up questions, to show empathy, to communicate clearly. HealthBench tries to assess that, what we call ecological validity. Ecological validity. Does the score actually mean something in the real world? Yes. Does performance on the benchmark genuinely predict how helpful or safe the AI would be in a real clinic or a real patient interaction? Is it a reliable indicator of what doctors consider good performance? And there was another point about older benchmarks getting saturated. Right. Many existing benchmarks were hitting a ceiling. The top models were getting scores close to 100%, which sounds good, but it means the benchmark isn't challenging enough anymore. It stops pushing the field forward. Ah, so it can't differentiate between the very best models or incentivize further improvements. Exactly. HealthBench seems to avoid that, for now at least. The fact that even the best models, like R3 scoring 60%, still have significant room to grow suggests it's an unsaturated benchmark. So it can keep driving progress for a while yet. That's the hope. It remains a useful measuring stick. The research also mentioned two specific versions, HealthBench Consensus and HealthBench Hard. What's the difference there? Good point. They offer different lenses. HealthBench Consensus zooms in on 34 specific behavioral dimensions. These are the aspects that the physicians involved reached a strong consensus on as being particularly critical for safety and quality. Things everyone agreed were non-negotiable. So it's like the must-have capabilities validated by expert agreement

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
