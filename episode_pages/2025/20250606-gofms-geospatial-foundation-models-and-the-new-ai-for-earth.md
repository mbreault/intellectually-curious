# GOFMs: Geospatial Foundation Models and the New AI for Earth

**Published:** June 06, 2025  
**Duration:** 19m 50s  
**Episode ID:** 17692461

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692461-gofms-geospatial-foundation-models-and-the-new-ai-for-earth)**

## Description

Geospatial Foundation Models (GOFMs) are large AI systems pre-trained on Earth-observation dataâ€”satellite imagery, maps, and time-seriesâ€”designed to learn transferable geospatial knowledge. In this episode we survey whoâ€™s building them (NASA/IMPACT/IBM/Clark University; Google; Atlas AI), what they can doâ€”from flood spread mapping and burn-scar detection to high-resolution land-cover tasksâ€”and the challenges of real-world data: quality, temporality, trust, and explainability. We also explore multimodal reasoning and natural-language interfaces that orchestrate geospatial analysis at scale for disaster response, agriculture, and environmental monitoring.

## Transcript

Okay, let's dive into something really at the forefront of computer science and software engineering right now. Sounds good. Look around us. I mean, literally every single day, we've got satellites, sensors, drones, just capturing petabytes of information about our planet. It's an absolute explosion of geospatial data, yeah. And that's your scale, right? The complexity of all this location-specific info. It's just, well, it's starting to overwhelm the traditional ways of analyzing things. Absolutely. We're kind of drowning in data but still finding it hard to get the insights out efficiently. Exactly. So, how do you even begin to make sense of it all? And this is where foundation models are popping up, you know, the AI tech behind things like large language models. They're being talked about as a potential game changer, specifically for analyzing all this geospatial data. That's the idea. And in this deep dive, we're aiming this specifically at you, pulling together insights from the stack of sources you gave us, research papers, project descriptions, blog posts, the works. Right. Our mission here is to really unpack geospatial reasoning with these AI foundation models. We want to explore, you know, what are these models? Who's actually building them? What can they do? Because some of it sound pretty amazing. Definitely. But also, just as importantly, what are the unique challenges? Because the real world, the geospatial world, it's messy, right? It's not just text. It really is. So, yeah, we'll get into the tricky parts, too. There were some genuinely fascinating details and maybe even some surprising facts that jumped out from the source material. Okay, so first things first, what exactly is a geospatial foundation model? Let's just break down that core concept to start. Well, if you think about foundation models generally, the sources describe them as these really large-scale deep learning models. Huge models. Huge. And their power comes from being pre-trained on just massive, massive amounts of diverse data. Because they've seen so much, they learn very general patterns and representations. Which means they're super adaptable, right? You don't need to build a whole new model from scratch for every single task. Exactly. You can often fine-tune them for lots of different specific jobs with minimal extra data. Or sometimes you just show them a few examples. That's the whole few-shot learning thing. Okay, so then a geospatial foundation model, or GOFM, just applies that idea to location data. Precisely. These are FMs that have been specifically trained on enormous amounts of geospatial stuff. Satellite images, aerial photos, maybe topographic maps, environmental sensor data, even street-level views. And the why here seems really key. Instead of building one AI model just to spot floods, and another one just to map crops, and another one for something else. Right. The GOFM learns the fundamental patterns across all that location data. It's learning about the Earth itself. Yeah, it's about learning a kind of a generalized understanding of the planet's surface, its features, how things change over time. And that general knowledge can then be a starting point for almost any specific geospatial problem you throw at it. Learning transferable geospatial knowledge. Okay, that makes sense as the basic idea. So who's actually building these things? What kind of projects are out there? The sources highlighted a few different groups. Yeah, there are several interesting efforts. One really significant one that focuses on Earth observation is this collaboration between NASA, IMPACT, IBM, and Clark University. They've developed models like Prithvi-Eo. Ah, yes, Prithvi-Eo. That's a great example. A GOFM trained specifically on Earth observation data, right? Using that harmonized Landsat Sentinel data, HLS. Exactly, HLS, multispectral data. Which means it's seeing the Earth in different wavelengths of light, stuff beyond what our eyes perceive. And it's doing this over huge areas, repeatedly. And the scale you mentioned, Prithvi-Eo 2.0 was what considered the world's largest geospatial AI model at one point. That's what the Clark University source pointed out, yeah. Trained on something like 4.2 million global time series samples from that HLS data. It wasn't just looking at static images. It was learning from how places change over time and incorporating location context right into the learning process. Pretty sophisticated stuff. So did training at that massive scale actually pay off? Did it lead to better results in the real world? It certainly seems like it did. They showed some really significant improvements in critical tasks like mapping how far floods spread or identifying burn scars after wildfires much more accurately. Okay. And the sources mentioned it outperformed, I think, six other geospatial foundation models in standard remote sensing benchmarks. So that suggests the huge pre-training really did capture valuable, transferable knowledge about the Earth. That's the whole promise, isn't it? That generalized knowledge paying off. The Clark team even took it further, right? Applying it to specific tasks. Yeah, they fine-tuned it for things like filling in gaps in satellite images where there are clouds or classifying different types of crops over a growing season. And apparently, fine-tuning Prithvi consistently gave better results than trying to train a specialized model from scratch for those tasks. And they're also working on explainable AI, XAI, trying to peek inside the model. Yes, and that's fascinating. They're developing benchmarks to understand how these models make decisions. Are they actually learning the underlying physics and geography? Like the unique spectral signatures of different materials? How things naturally change season to season? The spatial relationships between objects? Because you need to trust these things, especially for critical applications. Exactly. Understanding why a model gives a certain output is crucial for users to trust it and choose the right tool for their job. Okay, switching gears a bit. Google Research seems to be coming at this from a slightly different angle. They're focused on mixing FMs with generative AI, like LLMs, to speed up geospatial problem-solving. Yeah, Google obviously has this incredible foundation of geospatial data already, with maps, Earth, Street View, and so on. Right. Their research seems focused on leveraging FMs with that data and, importantly, allowing people to interact with it all using natural language. Using models like Gemini, their big language models, so the idea is Gemini becomes the sort of the front end. Kind of, yeah. You could ask it questions in plain English instead of needing specialized GIS software or coding skills to manage complex geospatial data and analysis workflows. And they've also built their own remote sensing FMs, trained on high-res imagery. Yes, models trained specifically on very detailed satellite and aerial images, often paired with text descriptions or labeled objects within the images. So these models are designed to really understand what's in those high-res pictures. And you can fine-tune those for tasks like mapping every single building or road or assessing disaster damage quickly? Exactly, those are key examples. But where it gets really interesting, I think, is what they call their geospatial reasoning framework. Okay, tell me about that. The sources describe it as using a model like Gemini to actually orchestrate the analysis. It acts like a conductor. Okay. It connects different specialized AI models, taps into various data sources, Google's own huge data sets, maybe your private data, public data archives, and it does all this based on natural language queries from the user. So can you give an example? That hurricane crisis manager one from the source. Oh yeah, that was a great illustration. Imagine you're managing disaster response. You could use this framework to first, say, visualize the area before the hurricane using satellite data from Earth Engine. Okay. Then overlay high-resolution aerial photos taken after the storm. The remote sensing FMs could automatically detect damaged buildings or flooded zones. Maybe you pull in predictions from their Weather Next AI about where flooding might get worse. Right. And instead of needing complex tools to put all that together... You could just ask Gemini things like, okay, estimate the percentage of homes damaged in this specific neighborhood or based on demographic data over here, suggest where we should prioritize sending relief supplies first. The LLM understands your goal and directs the right geospatial tools and data to answer it. Wow. That really lowers the barrier to entry. They mentioned testers like Airbus, Maxar, Planet Labs are already playing with this. Yeah, big names in the satellite imagery world are exploring these capabilities through their trusted tester program. It shows there's real interest. Now, another name that came up was Stefano Ermin, co-founder of Atlas AI and also at Stanford. They seem to be pioneers in this space too. Absolutely. Atlas AI is very focused on that intersection of geospatial data in deep learning, particularly FMs. Ermin's lab at Stanford develops SatMeE. SatMeE, right. That was highlighted as the first FM trained specifically for satellite imagery using a self-supervised approach. Correct. The goal there was really enhancing image recognition, helping the AI spot subtle patterns or anomalies in satellite photos that might be missed by traditional computer vision methods. Things that indicate change or risk. And Atlas AI sees a few key application areas for these GOFMs. They do. Forecasting is a big one. Using the time series nature of satellite data to predict things like crop yields, environmental changes, or even societal trends. Makes sense. Enhanced image recognition, building on models like SatMeE, is another key area. And then there's a really powerful concept they call contextualization. Contextualization. What does that mean here? It's about integrating different types of data. So not just analyzing the satellite image in isolation, but combining it with, say, text descriptions, economic data, weather patterns, using the multimodal capabilities of these models. Oh, okay. So you can ask it more complex things in natural language. Exactly. Like, show me all the new construction sites near major rivers in Southeast Asia over the last

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
