# DNA of an AI Agent: Inside Strand's Model-Driven SDK

**Published:** June 01, 2025  
**Duration:** 18m 44s  
**Episode ID:** 17692563

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692563-dna-of-an-ai-agent-inside-strand's-model-driven-sdk)**

## Description

In this Deep Dive episode we unpack Strand's Agents, an open-source SDK that puts the model in the driverâ€™s seat. We break down the three core ingredientsâ€”model, tools, and promptâ€”and walk through the agentic loop where the LLM plans, decides, and acts. Learn why Strand's was built to eliminate boilerplate, accelerate production-ready agents, and scale from local prototyping to real deployments. We'll cover model support, tool interfaces (MCP), the add_tool decorator, and real-world usage like AWS Q Developer, AWS Glue, and VPC Reachability Analyzer, plus tips for building and iterating quickly.

## Transcript

Welcome back to the Deep Dive. Today we're peeling back the layers on something new and pretty exciting, I think, specifically for us software engineers working in the AI space. That's right. We're going deep into Strand's agents. It's a new open source SDK, and it's really designed to, well, simplify things, make building AI agents faster. Yeah. If you're, you know, wrestling with integrating LLMs and tools or just trying to figure out how to make agents work more efficiently, this sounds like it's for you. Definitely. We've gone through the recent announcement materials for Strand's agents. And our goal here is really to unpack it. What is Strand's agents? Why now? How does it actually work under the hood? Exactly. We want to get past the buzzwords and show you the core thinking, the problem it solves, and, you know, what it might mean for how you build AI agents going forward. Okay, let's jump right in then. What is Strand's agents at its heart? So fundamentally, it's an open source SDK for building and running AI agents. But the really key characteristic, the thing the announcement stresses, is its model-driven approach. Model-driven. Okay, that sounds important. What does that actually mean for me as a developer? What changes? It's really a shift in, let's say, control. Instead of you, the engineer, needing to write really rigid step-by-step code. You know, first call this API, then parse the response this way, then make a decision based on rule X. Strand's basically trusts the model more. It's built to leverage the advanced capabilities that modern LLMs have baked in. Things like planning, chaining thoughts together, deciding which tools to call, even reflection. So you're offloading some of that complex orchestration logic onto the LLM itself, meaning maybe less boilerplate for me to write? Precisely. That's the idea. The source material points out you can often define an agent in just a few lines of code, because you're mostly just saying, here's the goal, here's the model, here are the tools it can use. And Strand's handles the flow. Strand's facilitates that flow, letting the model drive it. And it's designed to scale, too. From simple local prototyping all the way up to complex production deployments. And this isn't just theoretical, right? It's actually being used. Oh yeah, definitely. It's already in production inside AWS, powering parts of some pretty significant services. Like what? The announcement mentioned Amazon Q Developer, parts of AWS Glue, and the VPC Reachability Analyzer. So it's clearly built with real-world production demands in mind. That's good validation. I think the source used an analogy, too, something about DNA. It did, yeah. Nice visual. It compares Strand's to the two strands of DNA, connecting the two core pieces of any agent. The model's intelligence, its brain, if you will, and the tools that let it interact with the world, its hands. Right. Strand's is that structure holding them together, enabling the model to, you know, think and then do. Okay, that paints a clearer picture of the what's and the philosophy. But let's talk about the why. Why build something new? What was the pain point that led to Strand's? Ah, yeah, the origin story is quite interesting. The source traces it back to early 2023, with a team working on Amazon Q Developer. They were seeing these research papers, like React, showing that LLMs could do more than just generate text. They could actually reason, plan, and use tools. They could act like, well, agents. But I imagine trying to use those early LLMs as agents wasn't exactly plug and play. Not even close, no. Those early models weren't really trained for agentic behavior. You needed really complex, carefully crafted, prompted instructions. Right. You needed intricate parsers to try and reliably figure out what action the model wanted to take from its text output, which frankly could be brittle. Yeah, I can imagine. And on top of that, tons of custom orchestration code to glue it all together. Even with the first agent frameworks that started popping up, the source says it still took months to get an agent stable enough for production. Sounds like a real struggle. Months? Wow. That sounds painful. Just writing all that scaffolding to make the model behave? Exactly. And then a crucial thing happened. The LLMs themselves got much better very quickly. Newer models came out with significantly improved native abilities for reasoning, following complex instructions, and understanding how and when to use tools correctly. Okay, that was the turning point then. The models caught up. It seems so. Yeah. But here's the rub. The existing frameworks, the ones built to handle the limitations of the older models, they started getting in the way. That's exactly the problem they identified. Even though the models were now much more capable, development time using those older frameworks didn't really shrink. It still took months to get agents production ready because the frameworks themselves were built around that older paradigm of needing heavy manual orchestration logic. Interesting. So the tools built to help ended up becoming a bottleneck themselves. Pretty much. They were, as the source puts it, getting in the way of easily leveraging the power of the newer models. So strands was conceived specifically to sort of clear the path, let the model's capabilities shine through. That's the core motivation described. Build something from the ground up designed to directly harness these enhanced LLM capabilities. Remove the need for engineers to write so much of that complex, explicit orchestration code. And the payoff, what was the real-world impact of making that shift? Speed. A dramatic reduction in time to market. The source mentions teams going from needing months to ship a production-ready agent down to just days or weeks. Days or weeks instead of months. That's a huge difference. Massive. It means much faster iteration, getting features out, responding to user feedback, a big boost in agility for engineering teams. That speed up alone is compelling. Okay, let's get into the nuts and bolts then. How do strands actually work? What are the core concepts we need to grasp as engineers? Right. The source breaks it down neatly. An agent in strands essentially needs three things. One, a model. Two, some tools it can use. And three, a prompt telling it what to do. Okay, simple enough to start. Tell us about model support. Are you locked in? No, flexibility seems key here. Strands is designed to work with a variety of models, specifically those with good reasoning and tool usability. Such as? Well, models available through Amazon Bedrock, like Anthropic's Claude, especially versions with built-in tool use and streaming support. Also, Meta's Llama models. You can use local models via a Llama for development. Nice for local dev. Yeah. And it integrates with Leo LM, which opens the door to many, many other models. Plus, you can plug in your own custom model providers if you need to. Good flexibility there. Okay, what about tools? That feels like where the agent gets its ability to actually do stuff. Absolutely critical. And again, lots of options. Strands supports tools built using something called the Model Context Protocol, or MCP. Apparently, there are thousands of those already published. Okay. It also ships with, I think, over 20 pre-built example tools for common things, like working with files, making HTTP API requests, interacting with various AWS APIs, useful building blocks. Then for custom stuff, if I have my own specific logic. This sounds really nice. You can take pretty much any standard Python function and turn it into a tool for your agent just by adding a simple add tool decorator. Oh, nice. And just decorate the function. Seems so. That makes it super easy to integrate your existing code or build custom actions for the agent without a lot of hassle. That add tool decorator does sound like a big quality of life whim. Okay, model, tools, and the prompt. That's just your instruction to the agent, usually natural language. You know, summarize this meeting transcript and draft a follow-up email or troubleshoot this network connectivity issue between these two instances. You can also give it a system prompt for overall guidelines or personality. Got it. So you set up the model, give it access to tools, tell it the task with a prompt. How does strands then make the agent actually, you know, do the work? What's the mechanism? That's what they call the agentic loop. It's the core execution cycle. It's basically a continuous back and forth between strands, the model, and the tools until the agent decides the job is done. Okay, walk us through that loop step by step. Right. So strands kicks things off. It calls the LLM you've configured. It sends the model the user's prompt, any relevant conversation history or context it's built up, and importantly, descriptions of the tools currently available to this agent. So the model gets everything it needs to make a decision. What happens next? The LLM uses its reasoning power. It looks at the prompt, the context, the available tools, and figures out the next logical step. Which could be? It might decide, okay, I have enough info, I can just generate a response for the user. Or, more often in agentic tasks, it'll realize it needs to do something. Maybe plan out some steps, maybe reflect on what happened before, or crucially, it might select one or more of the tools it was told about. Ah, okay. And if it decides to use a tool, let's say call an API. Strands catches that decision. It sees the model wants to use, say, the make applicable tool with specific arguments. Strands then takes responsibility for actually executing that tool. It calls the function, gets the result. And then what? Does the result just disappear? No, no, that's key. Strands

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
