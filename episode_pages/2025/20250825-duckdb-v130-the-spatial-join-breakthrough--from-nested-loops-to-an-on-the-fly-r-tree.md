# DuckDB v1.3.0: The Spatial Join Breakthrough â€” From Nested Loops to an On-the-Fly R-tree

**Published:** August 25, 2025  
**Duration:** 4m 48s  
**Episode ID:** 17728254

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17728254-duckdb-v130-the-spatial-join-breakthrough-â€”-from-nested-loops-to-an-on-the-fly-r-tree)**

## Description

Spatial joins connect data by location. In this episode we unpack DuckDB's v1.3.0 dedicated spatial join operator, how it builds an inâ€‘memory R-tree and buffers the smaller table to probe it efficiently, and why this yields dramatic speedups (e.g., a 58M-row join against 310 neighborhoods dropping from ~30 minutes to under 30 seconds). We trace the journey from brute-force nested-loop to IE-join optimizations with bounding boxes, discuss current limits and ongoing work (larger-than-memory builds, more parallelism), and highlight implications for geospatial analysis.

## Transcript

Have you ever stopped to think about how powerful it is to connect data just based on location? Like imagine trying to find all your stores within certain delivery zones, or maybe mapping sensors inside a park boundary. This task, it's called a spatial join. And it's really fundamental in geospatial data science. It lets you enrich data sets, give them a real-world anchor. And speaking of anchors, DuckDB, which we know is this super fast in-memory analytical tool, well, they've just made a huge leap in handling these spatial things. Their latest release, v1.3.0, seems like a pretty big deal for this. Oh, it absolutely is a really big deal. So yeah, for anyone listening who works with location data, our mission today is basically to unpack how DuckDB, especially with this v1.3.0 release, took spatial joins from being this really tough, super time-consuming problem into something incredibly efficient, scalable too. It's all thanks to a new dedicated spatial join operator. And seriously, this isn't just some minor improvement. It's a genuine game changer for location-based analysis. Okay, right. Let's dive into that journey then, because the performance numbers I saw are just staggering. Take a common, well, maybe challenging scenario, like 58 million taxi trips in New York City, right? And you want to join them against, say, 310 neighborhood shapes. Before this new operator, how did DuckDB even try to do that? And why was it such a pain point? Yeah, that's the core issue right there. DuckDB, like a lot of databases, would often just default to what's called a nested loop join, brute force, essentially. And since checking if a point is inside a shape, that spatial predicate is computationally heavy, well, it meant comparing pretty much every trip with every neighborhood. For that 58 million row example you mentioned, on a standard laptop, you could be looking at, wait for it, 30 minutes, which just isn't practical if you're trying to analyze data iteratively. 30 minutes? Wow, yeah, that's basically unusable for quick analysis. So, okay, what was the first kind of clever fix the team came up with before this brand new operator? Right, so the intermediate step was something called an IE join optimization. It's pretty smart. It used bounding boxes, like simple rectangles around the shapes, to quickly filter out pairs that obviously couldn't match way earlier in the process. They leveraged DuckDB's existing inequality join smarts for this. And that managed to get the same 58 million row query down to under two minutes, which was a huge improvement, definitely. But it still involved sorting the data and had its own limitations, wasn't perfectly optimized for pure spatial stuff. Okay, under two minutes is way better than 30. But still, the real engineering magic, the big leap that came with this dedicated spatial join operator in 1.3.0. Absolutely. That's the breakthrough. This new operator is built specifically for spatial joins. It uses an R-tree index built on the fly. You can kind of think of it like how a hash join uses a hash table, but for spatial dimensions. It buffers the smaller table, builds this R-tree index in memory, and then probes it really efficiently with the points from the larger table. And that's how we get the massive speed up. That same 58 million row query now completes in less than 30 seconds. That's what, a 58x improvement over that original 30 minute nested loop time? It's remarkable. Less than 30 seconds. That is genuinely incredible. Going from half an hour down to that, it really changes what you can even attempt to do with spatial analysis, right? Exactly. It lowers the barrier significantly. Now, there are some initial things to keep in mind, like the current version works best when the smaller input, the one it builds the R-tree on, fits in memory. But the team is already working on ways to handle larger than memory builds and also improving parallelism, making it even faster on multi-core machines. And this optimization thinking extends to specific functions too, like STD within, which checks for points within a certain distance. That's already showing huge speed ups. In some tests, it's almost seven times faster than just checking for intersections, S-Intersect, because its implementation is so tailored. The potential there is huge. Okay, so let's quickly recap this deep dive then. We went from a potential 30 minute wait for a big spatial join in DuckDB down to maybe under two minutes with the IE join trick. And now with the dedicated spatial join operator in V1.3.0, we're often looking at less than 30 seconds, a 58x speed up, which is just fantastic. But it sounds like the work isn't finished yet. Not at all. It's an ongoing process. But this progress already makes connecting data by location so much faster, so much more accessible. So maybe the final thought for you listening is this. Now that these complex spatial queries are running orders of magnitude faster, what kinds of questions about our physical world, questions that seemed maybe too hard or too slow to ask before, can you start exploring with your data? What new stories are just waiting there to be uncovered when connecting things by location is this effortless? It really does open up a whole new realm of possibilities for geospatial analysis.

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
