# MCP Unchained: Cursor's Model Context Protocol for a Smarter AI Partner

**Published:** April 26, 2025  
**Duration:** 13m 35s  
**Episode ID:** 17692333

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692333-mcp-unchained-cursor's-model-context-protocol-for-a-smarter-ai-partner)**

## Description

We dive into Cursor's MCP, a plugin-like protocol that lets AI see your whole projectâ€”databases, Notion docs, GitHub workflowsâ€”through SDTO and SSE servers. Learn why this matters, how to set up JSON configs, and how MCP turns your AI from a code generator into an integrated, context-aware teammate.

## Transcript

Ever feel like your AI coding buddy, you know, the really smart one, is somehow missing the plot? Like it gets the code right in front of it, but the whole project, it just doesn't quite see the bigger picture. Yeah, absolutely. Like asking for database details, you know, are documented somewhere else. Exactly. Or suggesting something that, well, completely clashes with the roadmap you've got laid out in Notion. Right. Well, today we're actually diving into something that aims to fix that. Okay. We're looking at Cursor's model context protocol, MCP for short. MCP. All right. Think of it as giving your AI glasses, letting it see beyond just the code file. So it can understand the whole landscape, the tools, the project structure, everything. That's the goal. Essentially, it's like a plugin system for Cursor. A plugin system. Okay. So it can connect to external things like data sources, tools. Precisely. Databases, Notion, GitHub, you mentioned them, that kind of thing. Gotcha. So our mission today for you listening is to figure out how this MCP thing can actually, you know, change how you work. Right. We've all been there, manually spoon-feeding info to the AI. Oh, yeah. Tedious. MCP wants to make that history by letting Cursor just grab the context it needs directly. Okay. So let's dig in. Why should you, our listener, really care about MCP? I mean, convenience is nice, but what's the real impact here? Well, I think the truly transformative part is how it could fundamentally shift the kind of help AI can give you. How so? Imagine Cursor not just seeing code, but also understanding your project specs from Notion or maybe API details from your internal docs. Okay. It's like upgrading from a, you know, a brilliant intern who needs constant briefings. Right, needs hand-holding. Exactly, to an AI that has the institutional knowledge, almost like a senior dev. Ah, I see. So it could spot subtler things, suggest more complex stuff? Potentially, yeah. Things it just couldn't figure out before without that broader context. It's about making Cursor less of a tool and more of a integrated partner. And I was looking at the docs, and this bit surprised me. It says these MCP servers, the things doing the connecting, can be written in basically any language. Yeah. As long as it can use standard output or like serve a web page. Standard stuff. That seems incredibly flexible. So it doesn't matter if you're using Python or Go or Rust or whatever? Exactly. It really lowers the barrier. You don't have to learn some specific framework just to hook your tools into Cursor. If you can make it talk, Cursor can potentially listen. Okay, so we get why it matters, connecting Cursor to our world, giving it that context. Let's talk about some concrete examples. Make it real. Databases first. That sounds like a big one. Oh, definitely. Huge time saver, potentially. Instead of you manually typing out schema details or wrangling data formats for the AI. Which is always fiddly. Right. MCP could let Cursor just query the database directly. Ask it about the data model, generate code based on the actual live structure, all without leaving Cursor. Wow, okay. And Notion. So many teams use that for specs, user stories. Exactly. So imagine Cursor just pulling that info directly. Using your project plan from Notion to help write the code for a new feature. No more switching windows, copy-pasting requirements back and forth. Right. It's about making the AI aware of the whole life cycle, not just the coding bit. The planning, the docs, the shared knowledge, that all becomes context. And the GitHub examples they mentioned, creating PRs, managing branches, finding code snippets, that automates a lot of the necessary grunt work. Totally. It moves AI beyond just generating code blocks to actually participating in your version control workflow, like another member of the team almost. The memory example is interesting too. MCP letting Cursor remember stuff within a session. Yeah, that caught my eye. It could really help maintain context, right? As you jump between different files or tasks. Because we all do that. And how often do you find yourself re-explaining the same thing to the AI? All the time. So a memory function powered by MCP could make those interactions much smoother, more efficient. And then Stripe managing customers and subscriptions from a Cursor. That seems wild. It's stretching beyond just code. It really shows the versatility, doesn't it? Yeah. It's not just about code context. It's about connecting Cursor to any system that holds relevant info or offers useful actions for your job. So you could be coding a feature based on customer feedback pulled straight from Stripe, maybe. That's the kind of possibility it opens up. It feels a bit sci-fi, but it's grounded in this protocol. So as you're listening, you should probably be thinking about your own workflow, right? The tools you use constantly. Exactly. Where could that direct connection save you time or effort? What frustrates you now that this might solve? Okay, we see the potential. It's pretty compelling, but how does it actually work? Let's get into the mechanics, the architecture. Sure. So at its heart, an MCP server is like a translator. A little program sitting between Cursor and your tool, like your database or Notion. Cursor sends a request. The MCP server understands it, talks to the external tool, gets the response, and translates it back for Cursor. And there are two main ways they talk. SDTO and SSE. Right, SDTO first. The docs say it runs locally. Cursor manages it, uses standard output. Can you simplify that? What is standard output? Think of a simple command line program. You run it, it prints text to your terminal, right? Yeah. SDTO transport basically lets Cursor run that program and just listen to that text output directly. It's simple, it's local, great for tools just running on your own machine. Got it. Just reads the text dump. And then SSE. That sounds more networky. Runs remotely, can be shared, uses a URL. Exactly. SSE stands for server-sent events. It's a web standard that allows for a more persistent connection over the network. So the MCP server doesn't have to be on my machine. Nope. It could be running on another server, maybe even in the cloud. Cursor just connects to it using a web address, that URL. Oh, okay. So that's how teams could potentially share an MCP server for a common tool. Precisely. SDTO is great for your personal local stuff. SSE gives you that network flexibility for shared resources or remote services. The choice depends on what you need. Makes sense. So say you want to set one up. How do you tell Cursor about it? It mentions JSON configuration. Yep, JSON files. It's pretty straightforward. You basically create a file that lists your servers. Okay. Inside a main MCP servers object, you define each server. Give it a name you choose. Like my Notion connector? Sure, something descriptive. Then you tell Cursor how to run it. Usually a command, like maybe Node or Python or the path to an executable. Right. And then args, which are like the command line arguments you'd pass to that command. Okay. And environment variables too, for API keys and stuff. Yeah, that's crucial. There's an infield where you can securely provide things like API keys without hard coding them in the command itself. Very handy. And where do these JSON files actually go? I think it mentioned two spots. Correct. Two locations. If the tool is specific to one project, you put a file named MCP.json inside a .cursor folder within that project directory. So it travels with the project. Exactly. But if it's a tool you want everywhere, like maybe connecting to your personal task list or something. Right. Useful across all projects. Then you create a global MCP.json file in the .cursor folder in your main home directory. Cursor checks both places. Okay, config sorted. Now, how do you actually use these things once they're set up? Does Cursor just... No. Often. Yes. That's kind of the magic. The Cursor agent is designed to look at the available MCP tools, they show up in your settings, by the way, and figure out which ones might be relevant to your current request or context. So it might just use one automatically? It often will try to, yeah. If it thinks a tool can help answer your question or perform an action, it'll suggest using it. But what if I know I want it to use my Notion tool right now? Can I tell it? Absolutely. You can just prompt it directly in the chat. Say something like, at Notion tool, find the user story for feature X. Or even just describe what you want. Use my Notion connection to look up the requirements. You can refer to it by the name you gave it in the JSON or by its description. Got it. Now, what's this tool approval thing? By default, it asks first. That's right. And it's generally a good default. For safety and transparency. When the agent wants to use an MCP tool, it'll pop up a message saying, hey, I want to run this tool. Okay. And, importantly, you can usually expand that message to see the exact command or arguments it plans to send. So you know precisely what it's about to do before you click approve. Good to have that check. But there's also an auto-run option. The docs called it YOLO mode. Yeah, they did. If you enable auto-run, Cursor will just execute the tools it deems necessary without asking you each time. Faster, but maybe riskier. Exactly. You need to trust the tools and the agent's choices if you turn that on. But it can definitely speed up the

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
