# Draconian but Dependable: NASA's 10 Rules for Safety-Critical Software

**Published:** February 16, 2025  
**Duration:** 16m 34s  
**Episode ID:** 17692741

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692741-draconian-but-dependable-nasa's-10-rules-for-safety-critical-software)**

## Description

In this Deep Dive, we unpack NASA's ten rules for building rock-solid software where lives are on the line. From forbidding goto and recursion to fixed loops, no dynamic memory, one-page functions, and per-function assertions, these guidelines promote clarity, determinism, and verifiability. Learn how these safety-critical principles reflect core software engineering practices that benefit any developer.

## Transcript

Welcome back to the Deep Dive. We're continuing our series on computer science and software engineering. Oh, cool. With a look at something pretty fascinating. NASA's 10 rules for safety-critical code development. Yeah, it's a fascinating area where the stakes are incredibly high. Right. We're talking about code that controls spacecraft, airplanes, nuclear power plants. Okay. Systems where even the smallest error could have catastrophic consequences. So how does NASA make sure that this code is rock-solid reliable? Right. They've got this legendary set of 10 rules that act as this foundation for building software in these high-stakes situations. And what's fascinating here is that these rules, while geared towards life-or-death scenarios, actually reflect broader principles of good software engineering that can benefit any developer. The source material even calls them draconian. Yeah. But that makes sense given the potential consequences of a bug. Exactly. When lives are on the line, you can't afford to be lax. Right. Even the slightest possibility of error needs to be eliminated. Wow. The first rule really sets the tone, keep the code's structure super simple. Right. No goto statements, no jumping around. Right. And here's the kicker, no recursion. Now, I've always found recursion to be like an elegant solution in many cases. Yeah. Why is it such a no-go in this world of safety-critical code? Well, recursion can create complex call stacks that are difficult to analyze for potential errors. Okay. And remember, in safety-critical systems, verifiability is key. Gotcha. We need to be able to trace every possible execution path and ensure it leads to a safe outcome. Right. And recursion with its nested function calls can make that verification process incredibly difficult. Wow. Introducing a lot of cognitive load for anyone trying to understand the code. Oh, okay. So it's about choosing the most straightforward path. Yes. Even if it might mean sacrificing, you know, a bit of elegance in the code. Precisely. And this leads us to the second rule. Okay. Which focuses on keeping loops under control. Every loop needs a fixed upper limit. Okay. No endless loops allowed. Okay. You can imagine the potential problems with an infinite loop in a spacecraft guidance system. That's a terrifying thought. Yes. A runaway loop on a Mars rover millions of miles away. Right. Talk about a debugging nightmare. Exactly. A fixed upper limit ensures that the loop will always terminate. Gotcha. Preventing the software from getting stuck and potentially causing a catastrophic failure. Oh. It's a simple rule, but incredibly important for ensuring predictable behavior. Okay. Rule number three might raise some eyebrows. Yeah. No dynamic memory allocation after initialization. Right. No mallocs or its friends. Yeah. For many programmers, this is like a pretty fundamental tool. Sure. Can you break down the reasoning behind this restriction? Dynamic memory allocation introduces a level of uncertainty that's unacceptable in safety-critical systems. Okay. The size of available memory can fluctuate. Right. Allocation requests can fail. Right. And these uncertainties can lead to unpredictable behavior, even crashes. Oh, wow. Imagine a critical system running out of memory mid-flight. Oh. That's not a scenario we want to encounter. Yeah, that's not good. So it's all about eliminating those unknowns. Exactly. And sticking with a fixed, predetermined amount of memory from the get-go. Exactly. A fixed chunk of pre-allocated memory ensures predictable behavior. Gotcha. And eliminates the risks associated with dynamic allocation. Okay. It might seem limiting, but it's a trade-off for increased safety and reliability. Now, this next rule is one I can really get behind, the one-page rule. Uh-huh. No function can be longer than what fits on a single sheet of paper. Ah, yes, the one-page rule. This one often sparks debate. Right. But it speaks to a fundamental principle of software design managing complexity. Gotcha. Imagine trying to debug a function that sprawls across multiple pages. Right. It's a nightmare. You're constantly flipping back and forth, losing track of variables and logic flow. Uh-huh. It's a recipe for errors. You're speaking my language. I've been in those debugging trenches. Yeah. And it's not a pleasant experience. Right. I can definitely see how limiting function length would improve readability and make the code easier to reason about. Exactly. And that's not all. By limiting function length, developers are forced to break down complex tasks into smaller, more manageable modules. Right. This modularity not only aids in understanding and debugging, but also makes the code easier to test and verify, which is crucial in safety-critical systems. So it's not just about readability. It's about promoting good design practices that lead to more robust and maintainable code. Precisely. Now let's move on to rule number five. Okay. Which deals with a powerful tool for catching bugs early, assertions. Okay. NASA mandates a minimum of two assertions per function. Wow, that's a lot. I've used assertions in my own coding. Yeah. But I've never seen them used so extensively. Sure. What makes them so crucial in this context? Assertions act as internal checks within the code, verifying that certain conditions hold true at specific points during execution. Okay. Think of them as alarm bells that go off if something unexpected happens. Okay. If an assertion fails, it means there's a bug in the code and we need to investigate. Right. This helps us catch errors early in the development cycle. Gotcha. Long before they can cause problems in the real world. So it's like having a safety net built into the code itself. Exactly. Preventing errors from slipping through the cracks. Assertions help us build a more robust system by forcing us to explicitly state our assumptions about how the code should behave. Right. It's a proactive approach to error detection that's absolutely essential in safety-critical software development. This is really eye-opening. These first five rules have given us a lot to think about. Right. It seems like NASA's approach is all about eliminating ambiguity and uncertainty. Yes. Ensuring that the code behaves exactly as intended. Right. Every single time. That's a great way to put it. These rules might seem strict, but they're designed to eliminate any room for error in systems where even the smallest mistake could have dire consequences. And we're just getting started. We'll be back in part two to delve into the next set of rules. Great. So stay tuned. Done good. Welcome back to the Deep Dive. Yeah. We're deep in the heart of NASA's 10 rules for safety-critical code development. Right. Exploring how these guidelines shape software that quite literally has lives depending on it. Yeah. These rules offer a masterclass in defensive programming. Right. A mindset that's valuable even outside of mission-critical systems. In the last part, we covered the importance of simplicity. Yeah. Controlled loops. Right. And saying no to dynamic memory shenanigans. Yeah. Where do we go from here? Rule number six brings us to the concept of data hiding. Okay. You want to keep data objects on a tight leash, limiting their scope to prevent accidental modification from other parts of the code. So it's like creating a secure compartment for sensitive data. Right. Minimizing the blast radius if something goes wrong elsewhere. That's a great analogy. Okay. Think of it this way. If a piece of data is only accessible within a specific function, it's much less likely to be corrupted by errors or side effects from other parts of the program. Right. This promotes modularity and reduces the risk of unintended consequences. Gotcha. Both crucial in safety-critical software development. This makes me think about some of my own coding projects. Yeah. I've definitely learned the hard way about the dangers of global variables and unintended data modification. We've all been there. Yeah. And this principle of data hiding goes hand in hand with rule number seven. Okay. Which focuses on the often overlooked return values from functions. Right. It's easy to just assume everything went smoothly. Yeah. And ignore those return values, especially for like seemingly simple functions like printf. Yeah. In safety-critical systems, that kind of assumption can be dangerous. Right. Ignoring return values is like driving with your eyes closed. Oh, wow. Hoping for the best, but not really knowing what's going on under the hood. Yeah. Return values provide crucial feedback. Uh-huh. They tell you whether an operation succeeded or failed. So if we connect this to the bigger picture. Yes. It's about maintaining a constant awareness of the state of the system. Right. Never making assumptions. Yeah. Always verifying. Precisely. And this vigilance extends to rule number eight. Okay. Which might surprise some people. Okay. Taming the preprocessor. Oh, right. Now the preprocessor is a powerful tool. Yeah. But it can also make code harder to read, understand, and analyze. Yeah, it's like adding too many layers of abstraction. Right. You might end up with code that's, you know, elegant, but difficult to decipher. Yeah. Especially when you're trying to track down a bug. Exactly. And that's why NASA limits preprocessor use. Okay. They want clarity and transparency in the code. Right. If you relied heavily on macros and conditional compilation. Yeah. It can become incredibly difficult to trace the actual logic flow and verify that everything is working as intended. So it's about striking a balance between the power of the preprocessor. Yes. And the need for clear, analyzable code. Absolutely. And this brings us to a perennial source of both fascination and fear among programmers. Pointers. Oh, yeah. Rule number nine lays down the law. Only one level of defencing allowed and no function pointers. Now, pointers are a fundamental word of C and C++. Yeah. The language is often used in these safety-critical systems. Right. Why such a strict limitation on their use? Pointers give you direct access to memory. Right. Which can be incredibly powerful. But also incredibly dangerous if not handled with extreme care.

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
