# AI at Scale: Energy, Compute, and the ARC Breakthrough

**Published:** April 23, 2025  
**Duration:** 18m 29s  
**Episode ID:** 17693349

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17693349-ai-at-scale-energy-compute-and-the-arc-breakthrough)**

## Description

We unpack the ARC challenge and OpenAI's O3, examine the staggering compute costs behind giant AI systems, and explore how scaling laws, data-center power, and chip manufacturing intersect with nuclear-powered ambitions and thermodynamics. A hard look at how infrastructureâ€”and energyâ€”might shape the future of AI and society.

## Transcript

Okay, let's dive into this. Artificial intelligence. I mean, it genuinely feels like the pace has just gone into hyperdrive lately. It really does. Almost dizzying sometimes. And speaking of leaps, just recently, this thing called the Abstraction and Reasoning Corpus, ARC. Ah, yes, the ARC Challenge. A tough one. Right, think of it as a super hard test for an AI's ability to think abstractly and generalize. Stuff humans find relatively intuitive but machines struggle with. Exactly. And apparently, OpenAI's O3 model just cracked it. That's big news. Francois Chalet, who created ARC, saw it as a real benchmark for, well, genuine reasoning. And get this, the reports say it costs something like $3,000 per problem in compute power. Wow. Over three grand per problem. That really tells you something, doesn't it? It really does. It just highlights the sheer sophistication but also the cost involved now. Exactly. And that cost, it points directly to the incredible computational resources needed for these kinds of genuinely novel challenges. So infrastructure is key. Absolutely. It makes Sam Altman's infrastructure is destiny, quote, feel, well, spot on. The demand for compute, that raw processing power. It seems directly linked to these logarithmic jumps we keep seeing in AI performance. It's this empirical trend and it's driving massive, massive bets on energy. Right. And it's not just about faster chips, is it? It's these AI scaling laws everyone talks about. Yeah, the basic idea that if you throw more at it, bigger models, more parameters, vast amounts of data, more compute for training and inference. Yeah, you get better results. Significantly better, like a compounding effect. Precisely. And the big players, they're putting absolutely serious money behind this idea. Okay, give us some examples. The scale sounds immense. Oh, it is. Look at Elon Musk's XAI. They're building this colossus supercomputer. We're talking like 100,000 NVIDIA H100 GPUs. 100,000. Those are the top tier AI chips, right? The very ones. Specialized for this kind of work and the estimated cost. Somewhere around $4 billion. $4 billion. Just for one cluster. And that's just one example. Then you have Microsoft talking about potentially $80 billion for AI data centers this year. $80 billion this year? Yep. And Amazon Web Services, AWS, they're pouring over $11 billion into data centers just down in Georgia. These are just colossal numbers. It shows a fundamental belief that this AI scaling thing isn't slowing down. Not at all. They're betting the farm on it, essentially. Okay, but all that compute needs power. A lot of power, I'm guessing. You guessed right. That colossus cluster. Projections are around 150 megawatts. 150 megawatts. How much is that in real terms? Well, put it this way. That's roughly 7% of the entire power consumption of a city like San Francisco. Wow. Just for one AI project. And globally, current AI workloads are already estimated at 20 terawatt hours a year. That's about 10% of all data center power right now. And it's growing fast, I assume? The projections suggest it could double by 2028. This kind of exponential curve really puts a massive strain on our existing energy grid. So inevitably, the question becomes, where does all this energy actually come from? Exactly. And what's fascinating, really, is a potential shift in thinking, especially among these big tech companies leading the AI charge. How so? Well, there seems to be this growing acceptance, maybe even, dare I say, enthusiasm for nuclear power. Nuclear, that's interesting, given the history and public perception sometimes. Right. But the sheer scale of the energy needed seems to be forcing a rethink. The demand might just outweigh the traditional reservations. Okay, any concrete examples of this shift? Definitely. Look at Microsoft. They signed a 20-year deal with Constellation Energy. The plan is to essentially bring part of the Three Mile Island nuclear plant back online. Three Mile Island? Really? Yeah. They're aiming for about 835 megawatts from that site by 2028, specifically earmarked for their AI data centers. That's a statement. Amazon. Amazon bought a whole nuclear-powered data center campus in Pennsylvania. Potential capacity, a massive 2.5 gigawatt. Two and a half gigawatts. Okay, these aren't small moves. Not at all. And you see analysts picking up on this. Goldman Sachs, for instance, estimates data center power use will jump 160% by 2030. 160%. And some experts are throwing out numbers like AI workloads potentially hitting 4.5% of global energy consumption. Four and a half percent of all the energy the world uses. Just for AI. That's staggering. It really is. And this ties into something else. The need for incredible accuracy as AI gets more powerful. Right. OpenAI has those five levels of autonomy, from chatbots up to AI potentially running organizations. Exactly. And as you climb that ladder, the tolerance for error just plummets. Think about it. That example where a system is 99% accurate. Which sounds pretty good on the surface. Right. But if it has to perform a 100-step task, that 99% accuracy per step means it only succeeds, what, 36% of the time overall? Oof. Okay, I see the problem. For complex, critical tasks, you need way more than 99%. You need those extra nines, 99.9, 99.99, and so on. Especially if AI is driving parts of the economy or making crucial scientific discoveries, a tiny error rate can cascade. Makes sense. And the potential payoff is huge if we get it right, isn't it? We hear talk of trillions added to the economy. Absolutely. Trillions globally. And think about healthcare. Dario Emode from Anthropic and his work Machines of Loving Grace, he speculates about AI solving huge problems, cancer, longevity, fertility issues. Things that touch everyone. And given the U.S. alone spends nearly $5 trillion a year on healthcare. The potential impact is just transformative. If AI can crack even parts of those problems, wow. Okay, but let's circle back to the energy. If AI delivers on this economic promise, the demand just keeps rocketing up. That's the projection. If these scaling trends hold and the tech delivers, we might see global energy demand doubling, maybe even quadrupling per decade. Per decade. What was the historical doubling time? Much slower. Historically, it's been more like 30 to 50 years for global energy demand to double. So this is a radical acceleration. Completely radical. It paints the picture where by the end of this century, the energy economy could be fundamentally shaped, maybe even dominated by AI's needs. You mentioned individual clusters needing huge amounts of power, too. Yeah, some projections suggest individual AI clusters could need 100 gigawatts by the end of this decade. 100 gigawatts. That's the power consumption of a whole U.S. state, isn't it? Pretty much. We're talking about a shift potentially as profound in energy terms as the industrial revolution. Okay, but the energy footprint isn't just running the data centers, right? What about making the hardware itself? Excellent point. The sources definitely highlight that. Manufacturing these advanced chips, these GPUs, is incredibly energy intensive itself. How so? Well, you're dealing with transistors measured in nanometers. Building them requires this ultra-precise process called ultraviolet photolithography. And for the absolute cutting-edge chips, you need extreme ultraviolet or EUV lithography machines. And there's basically only one company in the world that makes them. ASML in the Netherlands. That's the one. It creates a real bottleneck. And then you've got the foundries like TSMC in Taiwan. Right, they actually make the chips for companies like NVIDIA. Exactly. TSMC is currently the sole producer of NVIDIA's top chips. The H100, the new H200, the upcoming Blackwall ones. And that takes a lot of power, too. A huge amount. TSMC already uses something like 8% of Taiwan's entire electricity output. 8%. Just one company. And that's expected to rise. Taiwan's actually planning to boost its peak power generation capacity by 12% or 13%, partly just to keep up with chip manufacturing demand. So the energy needs just ripple all the way down the supply chain. It really illustrates the depth of the energy challenge. And then there's this idea of an intelligence explosion. What's that about? It's the concept that at some point, AI might become smart enough to significantly accelerate its own research and development. AI designing better AI. Essentially, yes. Automating the process of innovation in AI itself. If that happens, the demand for compute could just explode. In a way that makes current projections look tame. So timelines we thought were centuries away could shrink dramatically. Potentially to decades or even faster. It's highly speculative, of course. But it adds another layer of urgency to this whole energy equation. Which brings us to a really fundamental problem, doesn't it? Beyond just clean energy sources. Yes. The thermodynamic limit. This is crucial. The material we looked at explains it well. Go on. Even if we had perfectly clean, unlimited energy, just using that energy creates waste heat. Thermodynamics 101. Right. Energy doesn't just disappear. It changes form. Exactly. And right now, the waste heat from all our technology already contributes about 2% of the warming effect we see from greenhouse gases. Only 2%. That doesn't sound like much. Not yet. But if our energy use keeps climbing exponentially, eventually, that waste heat itself becomes the dominant factor warming the planet. Because the Earth cools

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
