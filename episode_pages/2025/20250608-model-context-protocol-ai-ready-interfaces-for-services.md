# Model Context Protocol: AI-Ready Interfaces for Services

**Published:** June 08, 2025  
**Duration:** 20m 55s  
**Episode ID:** 17692660

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692660-model-context-protocol-ai-ready-interfaces-for-services)**

## Description

In this Deep Dive, we examine MCPâ€”the Model Context Protocolâ€”and why it matters for AI agents. We contrast MCP's strict, wire-based communication with traditional REST/OpenAPI, explore runtime discovery, deterministic execution, and the primitives (tools, resources, prompts) that let agents understand and safely act on your service in production.

## Transcript

Welcome to the Deep Dive. If you're a software engineer building services, you know the world is changing fast, especially with the rise of AI agents. These autonomous programs need to interact with the applications and systems we build every day. Yeah, absolutely. And that interaction piece, well, that's where things get really interesting and, frankly, challenging. How do you make sure these agents can connect reliably, figure out what your service actually does, and then execute actions safely? Exactly. Because the interfaces we've traditionally used, things like REST APIs or GraphQL, they were designed with a specific user in mind, us, human developers writing code. But AI agents, they operate differently, fundamentally so. And that creates some unique requirements that our standard APIs weren't really built to handle. And that's really the heart of this deep dive. We're looking at the source material you share to explore this space, focusing on the differences between those, let's call them traditional API approaches, and a newer concept designed specifically for AI agents, the Model Context Protocol, or MCP. Okay, so our goal today is to really unpack why this distinction matters more and more, especially for you, the SWE building these services. You know, what does it actually mean to create interfaces that AI agents can not just consume, but truly understand and use effectively, especially in production? Makes sense. So maybe let's start by digging into the problem that MCP is trying to solve. The source calls it the HTTP API problem. Okay, the HTTP API problem sounds a bit dramatic, but I'm intrigued. What's the core issue there when an automated agent tries to use a typical API? Well, just think about the sheer flexibility, or maybe a better term the source uses, is combinatorial chaos that you find in traditional HTTP APIs. Combinatorial chaos. Okay, break that down for me. What does that actually look like in practice when an AI agent is trying to, say, use an API? It means that even for something simple, like identifying a resource or passing a parameter, there are just so many ways the data can be encoded and sent in a single request. It could be in the URL path, right? Like user settings 123. Or maybe a query parameter like .userId123 and action update. Exactly. Or maybe it's tucked away in a custom HTTP header. And then you've got the request body. It could be JSON, it could be XML, it could be form data, it could even be plain text. And each of those has its own structure. Right. So for one logical task the agent wants to perform, the inputs it needs might be scattered all over the place. And, you know, the same piece of data might even look different depending on which endpoint you hit or which team built that part of the API. And, yeah, we have great tools like OpenAPI, Swagger, but the source makes a good point. They mostly describe the existing situation, right? They document the chaos. But they don't really enforce a standard way of doing things across different APIs or even within the same large API. Precisely. OpenAPI is fantastic for a human developer to read the map, understand the variations. But for an automated agent, it's like trying to parse a guidebook describing a city with inconsistent street signs and building numbers. It's not getting a protocol that guarantees a consistent structure for every single interaction. HTTP just wasn't designed for this kind of automated programmatic calling. It grew out of browser needs. Okay, so the big challenge is this inherent lack of structure and consistency in traditional APIs. It makes it hard for an AI agent to reliably figure them out and use them without needing complex, potentially fragile logic just for interpretation. So how does MCP, the Model Context Protocol, approach this differently? Well, MCP doesn't try to just, you know, add better documentation on top of inconsistent APIs. Instead, it defines a wire protocol. Think of it like defining the actual language and grammar rules that the agent and service must use to talk to each other. And those rules are strict. So it's less about describing what is and more about prescribing this is the one way we communicate. Exactly that. It uses something like JSON RPC 2.0 for the message format, making sure every action call looks consistent. Usually, you know, a method name and a single JSON object holding all the parameters. No more hunting around. The source highlights a few key architectural bits that enable this. Okay, tell me about those building blocks. Right, so first you've got the transport. It can be streamable HTTP, sure, but crucially, it also supports Stadio standard input output right out of the box. That's pretty different, and we'll definitely circle back to why that matters. Stravio, okay. Interesting. What else? Then there's discovery. Discovery for an AI agent. I'm guessing this isn't just reading a static spec file someone emailed over. Exactly. This is a really fundamental difference. MCP has standard built-in commands that the agent can just call at runtime to ask the service, hey, what can you do? An agent calls tools list, and boom, it gets back a structured list of all the available actions and their input requirements. Or resources list for read-only data. The service tells the agent its capabilities dynamically, right then and there. Huh. That sounds much more like how an intelligent agent would explore, you know? It doesn't need this preloaded, possibly out-of-date map. It can just ask, what tools do you have right now? You got it. And finally, there are the primitives. The source talks about three main types. Tools, which are the actions the agent can make the service perform, like create calendar event or search repo. Okay, actions. Makes sense. Then resources, which are basically read-only data points, like get user profile or list files. And prompts, which are like templates or structured ways the service can guide the agent if it needs specific output. That structure seems pretty logical. Tools for doing, resources for knowing, prompts for guidance. And you mentioned JSON-RPC 2.0 under the hood. For the SWE's listening, that's a lightweight protocol. It uses JSON for remote procedure calls. So that standardization helps enforce the consistency you were talking about. That's right. It gives you that predictable structure right on the wire. Now, obviously, when you introduce a new protocol, especially for services, the first question many engineers will ask is, okay, but why not just extend OpenAPI? We already have that whole ecosystem. Yeah, that's definitely the first thing that pops into my head. We've invested so much in OpenAPI, it's everywhere. Why reinvent the wheel? What does the source say about that? It gives three pretty solid reasons. First one goes back to what we just discussed. OpenAPI describes, MCP prescribes. You can have the most detailed OpenAPI spec ever, but it doesn't force an endpoint to put the user ID in the header versus the path. It describes the inconsistency. For agents, you need that enforcement baked into the protocol itself to guarantee consistent patterns. Okay, so describing the mess doesn't clean it up. Got it. Reason number two. Retrofitting just doesn't scale well. If you try to twist OpenAPI to really meet all these agent needs, runtime discovery, guaranteed single input location, proper bidirectional communication, standardized errors, you'd have to make such fundamental breaking changes. You'd basically end up creating a new incompatible protocol anyway. Ah, right. It wouldn't be OpenAPI as we know it anymore, and most existing APIs wouldn't support this new hypothetical version. Exactly. Which leads straight into the third reason, the ecosystem problem. Even if OpenAPI did somehow evolve into this perfect agent protocol, you've still got millions of existing APIs out there documented the old way. They wouldn't magically update. You'd have this massive legacy landscape that's still not agent-friendly. MCP sort of bypasses that by starting fresh, specifically with AI principles in mind. That makes a lot of sense. Sometimes it's just easier to build the right tool for the new job rather than trying to force-fit an old one, especially given the scale we're talking about. Okay, so the source then really digs into five fundamental differences that make MCP more suitable for AI agents. Let's walk through those. First up, runtime discovery versus static specs. Yeah, this one's huge for agents designed to be autonomous. With traditional APIs, if you add a new endpoint or maybe change the input schema for an existing one, the agent's understanding, which is usually based on a static OpenAPI file or maybe a generated client SDK, is suddenly wrong. It's outdated. Right, and updating it means regenerating code, maybe redeploying the agent, manually changing configs. It's a whole process, a real pain point, actually, in fast-moving development. Exactly. With MCP, because you have those standard tools list and resources list calls, the agent just asks the service at runtime. It gets the latest, freshest list of what the service can do right now with the correct schemas. It can discover and adapt to changes on the fly without needing a code push every time the service evolves. That dynamic nature is just way better suited for agents that need to adapt. That's a massive advantage for flexibility, definitely. And it decouples the agent's logic from the service's specific implementation details. Okay, second difference. Deterministic execution versus LLM-generated calls. This sounds critical, especially for production systems. Oh, absolutely critical. This might be the single biggest advantage if you're the SWE, exposing functionality to an agent. You see, with many current approaches, especially using function calling built on traditional APIs, the large language model itself is often tasked with, like, generating the raw HTTP request. It has to figure out the right URL, build the headers, format the JSON body, decide where each parameter goes. And LLMs, well, they're amazing, but they're probabilistic. They can hallucinate details, right? They might get a parameter name slightly wrong, forget a required field, use

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
