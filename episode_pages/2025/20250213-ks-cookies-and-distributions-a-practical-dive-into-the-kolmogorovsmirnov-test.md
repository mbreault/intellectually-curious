# KS, Cookies, and Distributions: A Practical Dive into the Kolmogorovâ€“Smirnov Test

**Published:** February 13, 2025  
**Duration:** 8m 37s  
**Episode ID:** 17692592

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692592-ks-cookies-and-distributions-a-practical-dive-into-the-kolmogorovâ€“smirnov-test)**

## Description

In this episode, we unpack the Kolmogorovâ€“Smirnov testâ€”the nonparametric tool that compares whole distributions rather than just means. Learn how one-sample and two-sample KS tests work, how to interpret the statistic with the Kolmogorov distribution, and when KS is the right fit versus more specialized tests. Through cookie-batch analogies and real-world applications, we explore pitfalls, parameter estimation, discrete data, and the versatile role KS plays in data analysis.

## Transcript

Okay, ready to dive into the Kolmogorov-Smirnov test. Let's do it. It's a really useful one, especially I think for statistics students. Absolutely, yeah. So to kind of introduce it, imagine you're trying to figure out if two batches of cookies came from the same bakery. Okay. But you can't see the recipes, right? Right. The KS test is kind of like a statistical taste test, comparing how the cookie characteristics are distributed in each batch to see if they match up. Yeah, that's a great analogy. So what's interesting about the KS test is that it's nonparametric, right? Exactly. Meaning that we don't need to know the exact recipe or like the underlying distributions of the data. We know. And it can handle different types of data. Yeah, and that's what makes it so powerful. So like the number of chocolate chips per cookie, the diameter of each cookie, or even a combination of both. Exactly, and that's something that, you know, a lot of other tests can't do. Right. You have to kind of specify beforehand what you think the distribution is. Yeah. But the KS test is really flexible in that way. So it could be used to see if a batch of cookies fits a known standard? Uh-huh. That would be the one sample test. Right. Or if two batches are likely from the same bakery, which would be the two sample test. Yeah, exactly. So it's not just telling us if the average number of chocolate chips is different between batches. Right. It's looking at whether one batch has like a wider range of cookie sizes or... That's a great point. ...or something like that. Yeah, it's not just about the average or the central tendency of the data. Right. It's also about the spread and the shape of the distribution. Okay, so it's sensitive to differences in both the location and the shape of the data. Precisely. Okay, so let's start with a one sample KS test. Okay. So how would you explain how that works? So think about plotting all your data points on a graph, like the diameter of each cookie in a batch. Okay. This creates what we call the empirical distribution function or EDF for short. Okay. Now imagine laying another curve on top representing the cumulative distribution function or CDF of a reference distribution. Uh-huh. Let's say the standard cookie size distribution for that bakery. Got it. The KS test compares these two curves to see how well they line up. So essentially we're looking for any big discrepancies between these two curves. Exactly. And how do we measure that discrepancy? So the way we measure this discrepancy is through something called the Kolmogorov-Smirnov statistic. Okay. Which is the maximum vertical distance between the EDF and the CDF. Okay. The larger this distance, the more evidence we have that our batch of cookies didn't come from that bakery's standard recipe. That makes sense, but how do we know if the distance is large enough to be meaningful? Right, so that's where the Kolmogorov distribution comes in. Okay. This distribution allows us to calculate the probability of getting a statistic as extreme as the one we observed if our batch of cookies actually did come from that bakery. Okay. And this probability helps us decide whether to reject the idea that our batch fits the bakery's standard, which is the essence of hypothesis testing. So the Kolmogorov distribution gives us a way to interpret the results of the KS test? Exactly. And make a decision based on the data. Exactly. Now there's also the Glivenko-Cantelli theorem, right? Yes. How does that come into play? So that's a really important concept, and it essentially tells us that as our sample size grows larger, in this case as we measure more and more cookies, the Kolmogorov-Smirnov statistic will get closer and closer to zero if our batch follows the bakery's standard. So the more data we have, the more confident we can be in our conclusions. Exactly. But is it risky to rely on a test that's sensitive to all sorts of differences? Yeah, that's an excellent point. Couldn't that lead to false conclusions? So while the KS test is versatile, its sensitivity can sometimes make it less powerful than other tests. Okay. That are designed to detect specific types of differences. I see. So there's always a trade-off between a general tool and a specialized one. It's like having a multi-tool. Exactly. Great for various tasks, but might not be the ideal choice for a very specific job. That's a great way to put it, yeah. So now what happens if we need to figure out the bakery's standard recipe based on our cookie batch? Right. How does that affect things? So that's another layer of complexity we need to consider. Okay. If we have to estimate the parameters of the reference distribution from the sample data itself, it can affect the critical values we use to make decisions about the null hypothesis. I see. We might even need to use computer simulations to get those values, depending on the situation. Okay, so that's something to keep in mind. Yeah, definitely. If you're working with a situation where you don't know those parameters beforehand. Right, you have to be a bit more careful about how you apply the test. So far we've been talking about continuous data like cookie diameter. Right. But what if we're dealing with something like the number of chocolate chips in each cookie? Okay. That's discrete data. Yes, exactly. Can the KS test handle that? Absolutely. Okay. The KS test can be adapted to handle discrete data or even a mix of continuous and discrete variables. Okay, so we could look at both the diameter of the cookie and the number of chocolate chips at the same time. Exactly. Interesting. It might require some more complex calculations, but there are statistical software packages available that can handle these situations for us. So you don't have to do it all by hand? Luckily not. That's good to know. So it's pretty flexible when it comes to different data types? Yeah, it is. Okay, so let's move on to the two-sample KS test. Okay, sounds good. So now we're comparing two separate batches of cookies and trying to determine if they likely came from the same bakery. Exactly. Using the same underlying recipe without knowing what that recipe is. Right. So is the process similar to the one-sample test? It is very similar. Okay. We still calculate a maximum distance between curves, but this time it's the maximum distance between the EDFs of the two samples. So we're not comparing to like a standard distribution anymore? Right, we're directly comparing the two sample distributions to each other. Okay, I'm following so far, but how do we decide if that distance is big enough to suggest the batches are truly different? So for that we consult critical values that are determined based on the desired level of significance, often denoted as alpha. Okay. And the sizes of our two samples. So the larger our samples, the smaller the difference needs to be to be statistically significant. Exactly. So even a small difference if we have a lot of cookies could be meaningful. Exactly. Interesting. And it's important to remember that the two-sample KS test is sensitive to all kinds of differences between distributions. Okay. Not just a specific aspect like the average number of chocolate chips. So it's kind of like our taste test can detect even the subtlest flavor differences between those two batches. That's a great way to put it, yeah. But that sensitivity can also have a double-edged sword, right? It can. So it makes the KS test versatile, but it can also make it less powerful than other tests that are specifically designed to detect certain types of differences. Exactly. So it's always a trade-off. So the KS test is good for getting a general sense of whether two distributions are different. Right. But if we're interested in a specific feature, there might have better tools available. Exactly. But overall, the KS test remains a valuable tool, particularly when we're working with limited information about the underlying populations. Yeah, especially when we don't know that recipe. Exactly. So we've really gotten to explore the KS test pretty in-depth here. Yeah, I think we've covered a lot of ground. What are some of the key takeaways for our listeners out there, especially the statistics students? Well, I think one of the biggest takeaways is that the KS test is a really versatile tool. You know, it can be applied to a wide range of data types. Right, and we talked about how it can handle continuous data, discrete data. Exactly. Even a mix of the two. And it's especially useful when we don't have a lot of information about the underlying populations. Right, we don't necessarily need to know that recipe beforehand. Exactly. So if our listeners are, you know, thinking about their research or they come across a problem where they're comparing distributions, the KS test should be on their radar. Absolutely. It's a great tool to have in your statistical toolbox. For sure. So how about some real-world applications? Oh, there are tons. Like, how could understanding the KS test help someone evaluate data they encounter outside of the classroom? Sure. So imagine you're comparing the effectiveness of two different marketing campaigns. Okay. You could use the KS test to see if the distribution of customer engagement metrics, like website clicks or purchase rates, are significantly different between the two campaigns. That's a great example. Or a researcher could use it to compare the distribution of test scores between two groups of students who received different teaching methods. So lots of possibilities there. Yeah, it's a tool that can be applied across many different fields. Right, to gain insights from data. Exactly. Yeah, it's not just a theoretical thing. It can really be used to make decisions and stuff. Absolutely. Cool. Well, I think this has been a really great deep dive into the KS test. Yeah, I agree. We've covered a lot of ground. We have, and hopefully it's been helpful for

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
