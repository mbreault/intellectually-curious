# Clockwork Math: How LLMs Add with Helices and Clocks

**Published:** February 12, 2025  
**Duration:** 12m 26s  
**Episode ID:** 17692598

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692598-clockwork-math-how-llms-add-with-helices-and-clocks)**

## Description

A deep dive into a surprising mechanism behind AI math: LLMs represent numbers as helices on a cylinder and add by rotating these helices. Weâ€™ll unpack the clock algorithm, how attention heads and MLPs choreograph the calculation, what activation patching reveals, and the implications for math reasoning, reliability, and future AI design.

## Transcript

All right, welcome to another deep dive, everybody. Today we're talking about something that's, well, it's gonna be pretty wild. Yeah, this one is really interesting. We're gonna look inside some LLMs and actually see how they do, well, addition. Yeah, you heard that right, addition. You know, like one plus one equals two. Exactly. And we're going to see the actual mechanisms these LLMs use to perform these calculations. So we're not just talking about, you know, throwing some numbers at a black box and hoping for the best. We're gonna really break it down. Exactly, we're going deep. Our main source material today is this paper titled, Language Models Use Trigonometry to Do Addition. I think our listeners are in for a surprise here. Trigonometry, I mean, I remember vaguely something about sines and cosines from high school, but how does that tie into LLMs? Well, it turns out these LLMs actually represent numbers visually as points on a helix. A helix, like DNA? Yeah, pretty much. Think of a spiral shape, kind of like a spring or maybe the threads on a screw. Okay, I can picture that. But how does a helix have anything to do with numbers? Well, imagine you take a number line and you wrap it around a cylinder. Okay. Each loop you make represents those repeating patterns we see in numbers, you know? Units, tens, hundreds, and so on. So this helix isn't just some random shape. It's literally representing the structure of our number system. Exactly, and this is what the researchers found. These LLMs use this helical representation for numbers. That's crazy. But how does that help them add numbers together? That's where this, what they call the clock algorithm comes in. Instead of directly adding numbers, they rotate these number helices. Rotate, like turning the hands of a clock? Yeah, precisely. It's like, imagine you have two numbers represented on separate helices. Okay. You rotate them in a certain way to combine them, and that creates a new helix representing the sum. Oh wow, like those rotating dials we see in figure one of the paper? That's actually really cool. But how did the researchers figure this out? They used a method called activation patching. Basically, they temporarily swapped out parts of the LLM. Oh, interesting. And they saw how that affected the model's output. It's a way to isolate the components involved in addition. And what they found was that this helix representation is crucial for the LLMs to calculate correctly. So they're not just generating random answers. They're actually using this shape to do the math. I mean, LLMs have tons of different components, right? Like, how do those fit into this whole clock algorithm thing? Yeah, so let's talk about two key players here. Attention heads and MLPs. Those are multi-layer perceptrons. Okay, so attention heads, they're kind of like the spotlight focusing on the numbers we want to add. Right. And then the MLPs, those are the workhorses processing all that information and manipulating those number helices. I see, so the paper lays out how these components actually work together to carry out this whole clock algorithm. It's like a really well-choreographed dance. Some of the attention heads, they're responsible for moving those helices representing the numbers to a certain place. Then the MLPs in certain layers, they come in and create a new helix. And this new helix represents the sum, like A plus B, you know? And then finally, you have other MLPs further down the line, and they read the final answer off of this new A plus B helix. Wow, that's amazing. The researchers, they even went a step further and looked at individual neurons within those MLPs, right? They did, yeah. And what they found was really interesting. The activation patterns of individual neurons, they actually mirror the helix. So it's like those neurons are reading the helix to do the calculation. Exactly, and that just adds further support to this idea that this is how these LLMs are adding numbers. Wow, it all fits together so beautifully. But why go through all this trouble with the helix and the clock algorithm? I mean, it seems kind of roundabout for just adding two numbers. Well, the paper puts forward an interesting hypothesis that they think this might be a form of error correction. Error correction, hmm, interesting. Yeah, you see, even if the LLM's representation of a number on that helix isn't perfectly precise, rotating them and reading the result from a specific point on that helix might be more reliable than just trying to add along a straight line. Like it's a built-in safety net. Exactly, and that's where we'll pick up in the next part of our deep dive. So, you know, it really makes you think, like how much more is going on under the hood of these LLMs than we realize? Yeah, and we always talk about, you know, the potential of AI, but seeing something like this, it really drives it home. Like we're not just talking about some simple algorithms here. This is getting pretty sophisticated. Absolutely, and, you know, we have to remember that this whole clock algorithm thing, it's based on their analysis of a very specific task, you know? Two-digit addition with a couple of mid-sized LLMs. Right, so it's not necessarily like a universal mechanism that applies to all LLMs and every type of math problem. Exactly, larger LLMs, I mean, they might be using different strategies altogether. And who knows what kind of mind-blowing things we'll find when we start dissecting those. Right, so this research, it's just the tip of the iceberg. And it begs the question, like, what are the broader implications of this discovery? I think one of the biggest questions this raises is, you know, do LLMs actually understand math or are they just, you know, incredibly good at mimicking it? That's deep, man. I mean, we've seen how these models can generate text that's practically indistinguishable from human writing. So could they also be developing some kind of, I don't know, mathematical intuition? It's a fascinating possibility. I mean, think about how humans often rely on visual representations and spatial reasoning when we're solving math problems. Right, like picturing those number lines or drawing diagrams. Exactly, and this clock algorithm with its helix and rotation, it kind of feels like an echo of that human approach, doesn't it? So maybe these LLMs are tapping into some similar cognitive process, but, you know, in this digital world. Yeah, maybe. But we need a lot more research to really understand the nature of these LLMs, you know, their true capabilities and their limitations. For sure. But even with those limitations, the discovery of this clock algorithm, I mean, that's huge. It gives us something concrete to study, to analyze, and to potentially even improve upon. Absolutely. It's a testament to the power of what we call mechanistic interpretability. You know, like the idea that we can actually reverse engineer these complex systems to understand how they work. And for our computer science student listeners out there, this is really relevant. It's not enough to just marvel at what these models can do. We need to understand how they do it. Right, we can't just be satisfied with, you know, oh, look, it works. We have to dig deeper, look at the algorithms, uncover those underlying principles that drive these systems. That's where the real insights are. Absolutely. So looking ahead, what does this mean for the future of LLMs? Well, one exciting possibility is that we could design LLMs that are specifically optimized for mathematical reasoning. So instead of just training them on massive amounts of text, we could actually incorporate mathematical principles and structures directly into their architecture. Exactly. Imagine the possibilities if we could develop LLMs that can not only crunch numbers, but actually grasp abstract mathematical concepts, prove theorems, maybe even contribute to new mathematical discoveries. Whoa, that would be game-changing, not just for computer science, but for any field that relies on mathematics. Right, and then there's the whole issue of trust and reliability. If we can understand how these LLMs arrive at their answers, we can have greater confidence in their output. It's all about making these models more transparent and accountable. Precisely, and that's absolutely crucial if we want to use these LLMs in critical areas like scientific research, medical diagnosis, financial modeling, you name it. Yeah, the stakes are high. We need to be certain that these models aren't just spitting out random numbers, but are performing these calculations in a consistent and verifiable way. Exactly, and understanding how they work can help us identify any potential biases or limitations, which will ultimately lead to more robust and reliable systems. So this journey into the world of LLMs and math, it's not just an academic exercise. It has real-world implications for how we develop and use these powerful technologies. It absolutely does. And you know what? As we continue exploring these LLM capabilities, who knows what other amazing discoveries we'll uncover. Yeah, I'm excited to find out. But before we jump ahead, let's take a moment to recap everything we've learned so far about this clock algorithm and its implications. Then we'll dive into the final part of our deep dive. So we've been talking about this amazing clock algorithm, right? How some LLMs use it for addition, representing numbers on a helix and then rotating them like clock hands. It's pretty wild. It is. And remember, this is all based on their analysis of two-digit addition. Right. And we know there are some limitations to the research. Larger LLMs or different tasks might use totally different methods. But

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
