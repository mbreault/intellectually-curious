# The AI Benchmark: Do PhD-Level Tests Really Measure Intelligence?

**Published:** March 06, 2025  
**Duration:** 10m 41s  
**Episode ID:** 17692728

üéß **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692728-the-ai-benchmark-do-phd-level-tests-really-measure-intelligence?)**

## Description

In this episode we dissect a rigorous study that puts large language models through the GPQA Diamond Dataset‚Äîa suite of PhD‚Äëlevel questions across physics, chemistry, and biology‚Äîto see how ‚Äúsmart‚Äù they really are. We explore three passing standards (complete accuracy, high accuracy, and majority), why 100% correctness isn‚Äôt guaranteed, and how models can be inconsistent even on repeated prompts. The episode also digs into prompting tricks, politeness effects, and formatting choices, showing why evaluation is nuanced, context‚Äëdependent, and essential for real‚Äëworld deployments.

## Transcript

All right, so you know how we're always talking about AI and whether it's actually living up to all the hype? Yeah. Well, this research you sent me is like a total deep dive into that, into how we even figure out if AI is any good. I gotta say, it's a lot more complicated than I thought. Oh, for sure. We're talking about large language models. You know, those AI systems that are like popping up everywhere. They're generating text, writing code, even trying to hold conversations. Yeah, it really feels like they're everywhere now. That's wild. But like, how do we actually benchmark them? How do we really know which ones are actually good and not just like fooling us with fancy language? Yeah, that's where benchmarking comes in. It gives us a way to, you know, assess and compare these different models. It's like setting a universal exam for all the AI students out there. I like that, a universal AI exam. So this research you sent, it focuses on a study that uses this seriously tough test. It's called the GPQA Diamond Dataset. And it's not just like, you know, basic trivia. We're talking PhD-level questions across physics, chemistry, biology, like stuff that would make my head spin. Yeah, it's designed to be really challenging. Like, you can't just Google the answers. It requires actual understanding and reasoning. Okay, so they're putting these AI models through the wringer with these super hard questions. What did they find? Like, did the AI pass with flying colors? Well, that actually depends on how you define passing. This study used three different standards. Complete accuracy, which means 100% correct. High accuracy, meaning 90% correct. And then majority correct, which is at least 51%. Okay, so like different levels of passing. And I guess the choice of standard really affects how well the AI seems to do, right? Because 51% might be great in some cases, but if we're talking about, I don't know, AI diagnosing medical conditions, I'd want to be way closer to 100%. Absolutely. And, you know, the interesting thing is this study used some pretty rigorous standards, like way more strict than some of the standards you see in computer science. Oh, yeah. You might have heard of things like pass at 100, where the AI gets like 100 attempts to answer a question correctly. Wait, so just one right answer out of 100 tries is considered a pass? That doesn't seem super reassuring to me. Well, it can be helpful in the early stages of, you know, development. But when it comes to real world stuff where accuracy is critical, like diagnosing patients or making financial decisions, we need way higher standards, like the ones they used in this study. All right, so how did the AI actually do on this super tough test? Were they acing those PhD level questions, like consistently? Well, that's where things get really interesting. Even the most advanced large language models, like GPT-4o and GPT-4 mini, they struggled to answer the questions correctly consistently. Hold on, you mean even when they were asked the same question multiple times, they didn't always give the same answer? Like they were kind of unpredictable? Exactly, and that's a key takeaway here. AI can be inconsistent, and that's a huge deal for real world applications. Imagine an AI system that's supposed to help with like legal decisions, but it gives different interpretations of the law every time you ask it the same question. Yeah, that's a little unsettling, to say the least. So how did this study even uncover this inconsistency? Do they just keep asking the same questions over and over again? Yeah, pretty much. They tested each question 100 times, which, you know, a lot of other studies don't do. They only test once, so they might miss this variability. Wow, so this study went deep, and it uncovered some pretty surprising things about AI consistency, or should I say inconsistency? Yeah, and they didn't stop there. They also looked at whether prompting tricks, like how we ask the AI questions could affect its performance. You know, things like being polite to the AI, like saying please answer this, or even, you know, I order you to answer. Wait, are you serious? Yeah. They were testing to see if being nice to the AI would make it smarter. That's wild. Did it work? It's pretty crazy, right? And on some individual questions, politeness did seem to have an impact. Sometimes it made the AI more accurate, sometimes less. But here's the thing. When they looked at the overall performance across the whole data set, those effects kind of disappeared. So being polite to the AI wasn't like a magic bullet. But the fact that it even had an effect on individual questions is still super interesting. What do you think that means? I think it shows that prompting is a lot more nuanced than we thought. It's not just about finding the magic words, but about understanding how the AI processes language, the context of the question, all of that. Okay, so even how we ask the question can make a difference in how well the AI does. So far, we've covered standards, inconsistency, prompting tricks. What else did this study look at? Well, they found something pretty interesting about formatting. Like when they consistently removed formatting instructions from the prompts, the AI actually did worse. Wait, really? So even something as simple as formatting can affect how well the AI understands and answers a question. Yeah, it's a good example of how even small things can impact AI output. It shows that those instructions, even the formatting, they really matter. Okay, so we've got a lot to think about here. It's not just about whether the AI gets the answer right or wrong. We have to consider the standards, the consistency, the phrasing, the formatting, everything. Exactly, it's all connected. And I think it's time we took a closer look at some of the specific findings from this study to really understand what's going on. I'm ready. Let's dive into the data. So remember all those different accuracy standards we were talking about before? Well, get this. At the highest accuracy level, the 100% correct one, neither GPT-4o nor GPT-4o mini actually performed better than random guessing. Oh, seriously? Yeah. So even those super advanced AIs couldn't consistently nail those PhD-level questions. I guess all that hype about AI being smarter than humans, maybe we need to take that with a grain of salt. Yeah, it really makes you think. It shows that even the most advanced AI has limits, especially when you hold it to a really high standard. But here's the thing. At lower accuracy thresholds, both models did do a lot better than just random chance. So it's like how well they do depends on where you set the bar. If the bar is super high, they struggle. But if you lower it a bit, they seem to do okay. Exactly. And it shows why it's so important to pick the right accuracy standard for whatever you're using the AI for. If it's something like healthcare or finance where getting it right really matters, well, that bar needs to be way up there. But for something like movie recommendations, maybe a lower threshold is fine. This definitely makes you think twice about all those headlines saying AI is surpassing human intelligence. Yeah, I think it's good to be a little skeptical. We need to look at the actual data and not just get swept up in the hype. Speaking of data, you mentioned some interesting findings about how the AI performed on individual questions. Anything really jump out at you there? Well, remember those prompting tricks we talked about? The please versus I order you kind of thing? The study found that for some specific questions, how the question was phrased really did make a difference in whether the AI got it right or not. So like just changing a word or two could affect how well the AI understood and answered the question? Yeah, sometimes being polite seemed to help the AI. Sometimes it actually made it worse, and sometimes it didn't seem to matter at all. It wasn't like there was one magic phrase that always worked. So there's more to it than just finding the right words. It was like the context of the question, how it's worded, maybe even just random chance plays a role. Yeah, it's complicated. And remember that example they gave about one question where saying please made a huge difference? Yeah, question hashtag 158, right? That's the one. Using please in the prompt led to a 61% higher success rate than using a more commanding tone. That's a big jump. Just for changing one word. It really shows how sensitive these AI systems are to even the tiniest changes in how we communicate with them. Exactly. It's not just about the raw information. It's about how it's presented, the tone, all of that. Okay, so let's step back for a minute and think about what we've learned. We're talking about incredibly complex AI systems that can do some amazing things. But it turns out evaluating how well they perform isn't as simple as we might think. Right. We can't just look at whether an AI answers a question correctly or not. We have to consider the standards being used, how consistent the AI is, how the questions are worded, all sorts of things. So what are the big takeaways here? What do we want our listener to walk away with after this deep dive into AI evaluation? I think one of the biggest things to remember is that evaluating AI, it's not like a simple yes or no, pass or fail kind of thing. There's so much nuance, so many factors at play. It's like we keep peeling back the layers and finding more and more to consider. We've talked about those different accuracy standards, how the AI can be inconsistent, how even the way we phrase things can make a difference. It's all connected. Absolutely. And it's a good reminder that we need to be

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
