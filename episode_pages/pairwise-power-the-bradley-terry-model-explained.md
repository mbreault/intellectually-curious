# Pairwise Power: The Bradley-Terry Model Explained

**Published:** May 03, 2025  
**Duration:** 18m 10s  
**Episode ID:** 17692251

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692251-pairwise-power-the-bradley-terry-model-explained)**

## Description

Take a close look at the Bradley-Terry model, the math that turns one-on-one preferences into a field of strengths. Weâ€™ll derive the core formula pi/(pi+pj), connect its exponential form to logistic regression and Elo, and show how Plackett-Luce generalizes to full rankings. Youâ€™ll learn how to estimate the scores via maximum likelihood, why iterative updates and normalization matter, and where this idea shows upâ€”from sports and market research to AI and animal behavior.

## Transcript

Think about how often we instinctively rank things. You know, comparing sports teams, deciding which snack we prefer. Often it just comes down to these one-on-one choices. Absolutely. It's a fundamental way we process comparisons. Okay, so let's unpack this. Today, we're diving into a really interesting mathematical model designed specifically for that. Analyzing these pairwise comparisons. It's called the Bradley-Terry model. That's right. It's a very neat piece of applied mathematics, and its reach is, well, quite surprising. So what's the core idea? How does it work? Well, at its heart, the Bradley-Terry model gives us a way to estimate the probability, really, the likelihood that one item, let's say item i, will be preferred over another, item j. Okay, preferred or chosen? Or maybe beats it in a sports context. Exactly. Preferred, chosen, beats it. It depends on the context. But the model links this probability to underlying scores or strengths that we assign to each item. Scores? Like a rating? Precisely. Let's say item i has a score, we can call it pi, and item j has pj. The model proposes a simple formula for the probability that i wins against j. And that formula is? It's just the score of i divided by the sum of the scores of i and j. So pi ij, pi, pi plus pj. Hmm, okay. So if pi is much bigger than pj, that probability gets close to 1. Exactly. A higher score means a higher chance of winning the comparison. It's quite intuitive, really. It translates those relative strengths into outcome probabilities. What's elegant, as you said, is how this relatively simple idea connects so many different fields. It really does. It's quite remarkable. You mentioned diverse fields. I immediately think sports rankings, naturally. Yes, definitely sports. Ranking teams in basketball, players in chess. That's a classic application. But where else does it pop up? Oh, lots of places. Think about market research or consumer science. You wonder what chocolate people prefer? Or at least wine. You could give them pairs to compare. Precisely. Paired comparison surveys. The Bradley-Terry model takes that data, you know, preferred chocolate X over chocolate Y, and estimates an underlying preference score for each chocolate. Interesting. So beyond snacks. Definitely. It's used in analyzing social dynamics, like dominance hierarchies in animal behavior studies. Who pecks whom in a group of chickens, that sort of thing? Kind of, yeah. And even more technical areas, too. Ranking academic journals based on citations or prestige. Ranking different AI models based on performance benchmarks. AI models, wow. Yes. And even figuring out document relevance in search engines. Sometimes pairwise judgments are used to train those systems. There's also a system called GATL used for judging, which relies heavily on this model. So from chickens to AI, that's quite the range. Okay, let's talk history for a moment. Bradley and Terry, 1952. That's right. Ralph Bradley and Milton Terry published it then. Though, interestingly, the core mathematical idea was actually studied earlier by Ernst Zermelo. The Zermelo, the set theory guy. The very same. He looked into similar problems related to chess rankings back in the 1920s. But Bradley and Terry really formalized this model. Got it. Now, you mentioned the formula, pr, ij, pi, pi plus pj. But I saw another form involving exponentials. Ah, yes. That's the form Bradley and Terry actually used in their paper. They set the score pi equal to e, raised to the power of another parameter, let's call it beta i, beta tau. So pi e. Okay, why the extra step? It gives the formula some nice properties. The probability then becomes ee, ee plus e. If you then take the logit transformation of this probability. The log odds, right? Log e1p. Exactly. The logit of paj just simplifies very neatly to payday. So the log odds of winning is just the difference in these underlying beta parameters. Precisely. It directly represents the difference in strength on a logarithmic scale. This form also highlights a connection to logistic regression. How so? Logistic regression predicts probabilities based on features, doesn't it? It does. It's a similar mathematical structure, but used differently here. In logistic regression, you usually know the features, like the beta values, and predict the probability. With Bradley-Terry, we usually observe the outcomes, who won, and we want to infer the underlying strengths, the bay values. Ah, okay. Different direction of inference. Right. And just as a side note, this exponential form is mathematically equivalent to the ELO rating system used in chess, just with a different scaling factor. ELO uses a base of 10 and a scale factor, often 400. Interesting connection. So these models handle pairs well. What if you need to rank, say, five items all at once based on some preference data? Does Bradley-Terry extend? Not directly, but there's a closely related model that does, the Plackett-Luce model. Think of it as the generalization of Bradley-Terry for ranking more than two items. So it gives you the probability of a full ranking, like item A, C, B, D. Exactly. It assigns a probability to every possible permutation or ranking of the items. That sounds potentially complicated. Is there an intuitive way to grasp it? There is. One good analogy is the urn model. Imagine you have an urn with colored balls, where the number of balls of each color corresponds to the item's strength score, its p-value. To get the top-ranked item, you randomly draw one ball. The probability of drawing a specific color depends on its proportion among all balls. Let's say you draw a red ball first. Red is ranked hashtag one. Then you draw again. You draw again, but without replacing the red ball. Now the proportions have changed slightly. You draw the second ball, say it's blue. Blue is ranked hashtag two. You continue this until all balls are drawn, giving you a full ranking. The Plackett-Luce model calculates the probability of getting that specific sequence. That helps visualize it. So the probability changes at each step. It does. Another way to think about it is the exponential race. Each item i is like a runner whose speed is proportional to its score pi. They all start a race at the same time. The first one to cross the finish line is ranked highest, the second is ranked second, and so on. You can mathematically sample rankings this way. Neat. And how does this relate back to Bradley-Terry? The Bradley-Terry model is actually a special case of Plackett-Luce. If you only consider rankings of two items, pairwise comparisons, the Plackett-Luce formula simplifies exactly to the Bradley-Terry formula. Ah, consistency. Okay, so we have these models. But in practice, we usually start with the data, right? The results of comparisons, who beat whom, which product was chosen. How do we get the scores, the pi or L a values from that data? Right, that's the most common task, inference. We need to estimate those scores. The standard method is maximum likelihood estimation, or MLE. MLE. Finding the parameters that best explain the data we saw. Exactly. You write down a function, the likelihood function, which essentially says, given a particular set of scores, p1, p2, pm, what's the probability of observing the exact win-loss outcomes that we actually recorded? And we want to maximize that probability. Precisely. We find the set of p values that makes our observed data look most likely, according to the model. We often work with the logarithm of likelihood, the log likelihood, because it's mathematically easier. Is there a formula to just calculate these best scores directly? Unfortunately, no. There's no simple closed-form solution. However, Zermelo actually proved way back that this log likelihood function has a unique maximum. So there's a single best set of scores. But we can't just calculate it. We have to find it iteratively. We start with some initial guess for the scores. Maybe all scores are equal to 1, for instance. Okay, like a baseline. Yes. Then we use an update rule, derived from the mathematics of the likelihood function, to refine those scores based on the observed win-loss data. We repeat this update process over and over. Until the scores stop changing much. Exactly. Until they converge. The scores gradually adjust until they settle on the values that maximize the likelihood. I saw a couple of different iterative formulas mentioned. Any practical difference? There are a few variations. One comes directly from setting the derivatives of the log likelihood to 0. But there's another one that often converges faster in practice. What does that faster one look like, roughly? Roughly speaking, it updates a team's score, say pi, based on a ratio. The numerator involves the sum of scores of teams it beat, weighted appropriately. The denominator involves the sum of scores of teams it lost to, again weighted. It's a bit more complex than that, but that's the gist. And there's a normalization step. Yes, that's important. After each iteration of updating the scores, we usually normalize them. A common way is to divide all scores by their geometric mean. Why normalize? It keeps the scores on a consistent scale. Without it, the scores could all drift upwards or downwards together in each iteration, making convergence harder to track. Normalization anchors them, usually so they multiply to 1 or sum to a constant log score value. The example with the four teams, A, B, C, D, really helped clarify that. You start with 1, 1, 1, 1, apply the update formula using the win counts. Right, you calculate a new score for A based

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
