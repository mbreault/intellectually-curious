# Forecasting the City in Minutes: Lyftâ€™s Real-Time Spatial-Temporal Forecasting

**Published:** May 06, 2025  
**Duration:** 13m 32s  
**Episode ID:** 17693190

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17693190-forecasting-the-city-in-minutes-lyftâ€™s-real-time-spatial-temporal-forecasting)**

## Description

A deep dive into how Lyft forecasts demand and driver supply across hyper-local geographies (geohash-6) every five minutes, with predictions updated each minute. We explore the trade-offs between fast, updating time-series models and deeper neural networks, why latency and engineering costs matter, and how data characteristics like spatial correlation and geography shape model choice. Learn how these live forecasts power dynamic pricing and driver incentives in a scale-rich marketplace.

## Transcript

Welcome to the Deep Dive. Today, we're tackling a concept that powers quite a lot of the tech we use, maybe without even realizing it. Real-time spatial temporal forecasting. Hmm. Sounds technical, but the core idea is pretty straightforward, isn't it? Yeah, essentially predicting what will happen, where it will happen, and when. Specifically, like right now or in the very near future. Exactly. It's the science of anticipating events across both location and time. And this allows for, well, proactive decisions in systems that are constantly changing. And for this deep dive, our insights are coming straight from the engineering team at Lyft. Ah, okay. So, real-world application. Definitely. I mean, Lyft runs this huge ride-sharing network across North America, and their whole operation basically hinges on this kind of forecasting. So, their perspective is going to be really practical, based on large-scale, everyday use, not just, you know, lab experiments. Right. It shows this isn't just some theoretical exercise. They're dealing with the messy reality of a live marketplace. Absolutely. Conditions can just flip in moments. So, yeah, their experience gives us a valuable window into how these advanced forecasting techniques actually get implemented, and the challenges, too. And the core problem they're grappling with is just understanding these incredibly intricate, rapidly evolving market dynamics. Think about, like, demand for rides after a big concert lets out, or how sudden rain changes everything. Right. Or just rush hour patterns. Exactly. Lyft needs to predict these shifts to make sure they have, you know, enough drivers in the right spots at the right moments. Efficiency is key. And the level they operate at is, well, it's pretty remarkable. They're forecasting market signals down to what they call a geohash 6 level. Which means, like, how small an area are we talking? Think roughly the size of a few city blocks. Tiny zones. And they're predicting demand and supply for each of those zones. Okay. Wow. And how often? For every five-minute window into the future. And get this, the predictions themselves are updated every single minute. Whoa. Okay, wait. Four million geohashes, you said. Per minute. For each signal they track. That's the scale they mentioned, yes. Predicting both, say, demand and driver supply at that level of detail, constantly refreshing. The sheer volume is just staggering. The compute power needed must be immense. It really underscores the need for efficiency, doesn't it? Yeah. Highly accurate models are great, but only if they can actually deliver the forecast fast enough to act on it. Right. Latency becomes a huge bottleneck. A key constraint, definitely. And these predictions aren't just sitting in a database somewhere. Lyft uses them very practically. The sources mention things like dynamic pricing. Where the ride cost adjusts based on that real-time supply and demand picture. And also real-time driver incentives. So basically nudging drivers towards areas where they're needed most. Exactly. Those are tangible impacts. It's how they manage the network proactively, trying to balance things out. Better for riders, better for drivers, ideally. Okay, so let's get into their findings. They looked at different types of models, right? Primarily traditional time series models versus deep neural networks, DNNs. Yes, that's a pretty common comparison in forecasting these days. How do the sort of established, often simpler time series methods stack up against the more powerful but also more complex machine learning approaches like DNN? And one of the big things they hit on is this trade-off. It's forecast accuracy versus what they call engineering cost. Right. So DNNs might, in theory, give you the absolute best accuracy if you just look at that number in isolation. But they often need way more computational resources. Training them takes time. Specialized hardware like GPUs. It's expensive. Plus, running them can add latency. And they can be harder to maintain, more prone to weird failures. That's part of the engineering cost too, yeah. Liability, maintenance overhead, debugging complexity. It all adds up. It's a really crucial point for real-world systems, isn't it? If you need to react now, a slightly less perfect forecast that arrives instantly is often way more valuable than a theoretically perfect one that shows up too late. Precisely. Actionability is paramount in real-time operations. And this is where it got really interesting for me. When they factored in that need for speed, that low latency, they found something perhaps a bit counterintuitive. Well, when they updated the models very frequently, like every single minute for the time series models, in some cases those quote-unquote simpler models could actually end up being more accurate overall than the DNNs. Ah, yes. That's fascinating. It highlights the power of agility, you can say. How so? Because the ground truth, the actual demand and supply, is changing so fast, especially at that hyper-local level. The model's ability to quickly learn from the very latest data becomes incredibly important. So responsiveness trumps complexity in that scenario. It suggests that, yeah, in highly dynamic environments, being able to react quickly can sometimes outweigh the ability of a more complex model to capture maybe more subtle, longer-term patterns if that complex model takes longer to update. They saw the time series models really shone for those very short-term predictions, right? Like the next 5 to 30 minutes, maybe up to 45. Exactly. They put that down to strong near-term autocorrelation. Meaning, like, what's happening right now is a good predictor of what's happening in the next few minutes. Pretty much. Like the weather example you used, if it's pouring rain right here right now, odds are very high it will still be raining here in 5 minutes. Time series models, especially when refit constantly, are great at latching onto those immediate trends and continuations. Yeah, they're designed for that time dependency. So if there's a sudden event, a local spike... That model refitted just a minute ago can pick up on that surge almost immediately. A DNN updated less frequently might miss that initial jump or react slower. Okay, but it wasn't a total win for time series, was it? What about longer forecasts? No, that's where the picture shifted. For forecasts looking further out, maybe beyond 45 minutes or an hour, they found the DNN models could actually pull ahead in accuracy. And the thinking there is? The thinking is that over longer horizons, other factors become more dominant. Things like daily or weekly seasonal patterns, overall trends, and maybe how conditions in one part of the city affect another part, those spatial correlations. And DNNs are generally better at learning those kinds of complex, interconnected relationships from lots of data. That tends to be their strength, yes. They can often capture more intricate patterns that simple time series models might miss over longer periods. So it really underscores that there's no single best model. It totally depends on your prediction horizon. Absolutely. For immediate operational tweaks, you want speed and reaction to the latest signals, often favoring those rapid refit time series models. But for more strategic planning, looking further ahead. The deeper pattern recognition of DNNs might offer an edge. It's about matching the tool to the specific job. They also saw differences depending on what they were forecasting, demand versus supply. What did they find there? Both model types apparently did better forecasting driver supply, which they said tends to be smoother, more stable. That makes sense. Oh. Driver behavior might have more predictable patterns. Yeah, but for rider demand, which can be way more volatile and spiky. Let me guess. The time series models often came out on top there. You got it. Especially those frequently updated ones. Seems they could handle the rapid fluctuations better. It likely comes down to the inherent predictability. Rider demand is just influenced by so many individual, often unpredictable decisions and external factors. Supply might follow more regular rhythms. And the data characteristics themselves matter hugely. They mentioned traffic speed, for example. How so? Well, traffic speed tends to have strong spatial correlation. Slow traffic here means slow traffic nearby. And it's maybe more stable over time compared to something like rideshare demand, which can just appear or disappear suddenly. Right. The inherent nature of the signal is fundamental. Is it noisy? Is it stable? Does it correlate strongly over time or space? That dictates how easy it is to forecast, almost regardless of the model. And here's a really specific kind of intriguing point they made. Go on. In areas with a complex terrain, think cities with lots of hills, water barriers, that kind of thing, the DNN models tended to underperform compared to the time series models. That is interesting. Any speculation why? Their thought, or at least one interpretation, is that the complex geography might disrupt the smooth spatial patterns that some DNN architectures are really good at learning. Ah, so the assumptions built into the DNN about how areas relate might break down where geography gets complicated. Yeah, potentially. And in those cases, the more localized focus of the time series models, especially when updated constantly, might actually do a better job capturing the specific nuances of those tricky areas. That makes sense. Yeah. It suggests the model needs to match not just the time horizon, but also the spatial characteristics of the environment. So the big takeaway on model performance seems to be it's really tangled up with the specifics of what you're predicting, the signal's stability, its patterns in time and space. You really have to understand your data. Precisely. It's not just about grabbing the fanciest algorithm off the shelf. It's about a deep understanding of the data's properties and picking the model that best captures those properties for the specific task you need it for. Okay, let's shift gears a bit to the engineering side. Because running all this at Lyft scale, that sounds like a massive headache. Oh, undoubtedly. The challenges are significant. They specifically highlighted the computational cost. Especially for the

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
