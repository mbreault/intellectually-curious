# Spin and Schemes: Inside the Robot Table-Tennis Breakthrough

**Published:** October 13, 2024  
**Duration:** 11m 58s  
**Episode ID:** 17692142

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692142-spin-and-schemes-inside-the-robot-table-tennis-breakthrough)**

## Description

A deep dive into a high-tech table tennis robot: 17 distinct shots, adaptive strategy, and real-time exploit of opponents' weaknesses. We trace its trainingâ€”from millions of simulated plays to seven cycles of iterative groundingâ€”and how researchers bridged the sim-to-real gap with domain randomization. Against 29 human players of varied skill, the robot wins some rounds and exposes limits, revealing what it takes for machines to learn, adapt, and compete in a sport that still rewards human intuition.

## Transcript

Okay, so picture this. You walk into your local sports center and you're feeling bold. Feeling bold, okay. Right, like you could take on anyone. But here's the twist. Okay. Your opponent, a robot. Wow, okay, that's not the average Tuesday thought, I'll admit. But get ready, because today we're diving deep into the world of robot athletes, or at least one very specific one. We're talking about a robot table tennis player. I am ready, let's do it. That's not just playing, but learning. Adapting its strategy against human opponents. Okay, well that is a pretty amazing leap forward, I'll say. Yeah. We're talking about a robot that uses a library of 17 different skills. Whoa. Everything from forehands and backhands. Oh wow. To those tricky topspin and underspin returns to go head to head with us humans. 17 different ways to return a shot? This robot's got to move for every play. Yeah. But how does it choose which skill to use in any given moment? That's what blows my mind. Yeah, that's the really fascinating part. So this robot, it keeps track of how well each skill works. Okay. And not just in general, but against you specifically. What? Like it's building a playbook, yeah, based on your weaknesses as you play. Okay, now that's intimidating. Yeah. So if my backhand is a little shaky. A little shaky, yeah. It's going to pick up on that. Oh yeah, it's going to exploit it. Absolutely, it's constantly analyzing your game and adjusting its own strategy in real time. Okay, so how do you even start teaching a robot to play table tennis at this level? I mean, are we making it watch hours of professional matches? Like is this some kind of robotic table tennis prodigy situation? You would think so, right? Right. I mean, it makes sense. But actually, they did most of the training in a simulated environment. Okay. So picture this, if you will. A virtual version of the robot, the table, everything. And it can practice its skills millions of times without wearing down any equipment. So like a supercharged video game version of table tennis. Precisely, like a supercharged video game version of table tennis. But here's the thing, they didn't rely on simulations alone. Right. They used a technique called iterative grounding. Iterative grounding. Which basically means they kept testing the robot against real human players and feeding that real world data back into the simulation. So they're constantly going back and forth between the virtual and real worlds, just making sure this robot can handle whatever we humans, you know, throw at it. You got it. And get this, they went through seven cycles of this training, evaluation, and data collection process. Wow. Result, a massive data set of over 28,000 ball trajectories. Talk about dedication. Wow. But why go through all that trouble? I mean, why not just train it entirely in the real world from the get-go? So time is a major factor here. Okay. Training solely with real world matches would have taken ages. Plus, you know, imagine the wear and tear on the equipment. And the researchers actually mentioned this. Early attempts to train similar robots just through real world human interaction weren't very efficient. Interesting. Like trying to teach someone a new language by just throwing them into a conversation with no prior learning. It's just not the way to go. Not the most effective method, yeah. Right. A recipe for disaster, maybe even a frustrated robot. But if you're training in a simulation, how do you make sure that actually translates to, like, the real world? What's to stop the robot from, you know, completely misjudging the physics of a real game? That's a great question. And it's actually a really common challenge in robotics known as the Sim2Real gap. Right, Sim2Real gap. Yes. And to bridge that gap, the researchers used a few clever techniques. Okay, I'm all ears. Give me the highlights. Well, for starters, they meticulously calibrated their simulation to match the real world physics of the game. Okay. We're talking about fine-tuning everything from the friction of the table to the bounciness of the ball. So they basically made the virtual world as close to the real thing as possible. Exactly. Yeah, okay. Exactly. But they didn't stop there. They also used something called domain randomization. Domain randomization. Okay, that sounds a little more high-tech. Break that down for me. Okay. So imagine you're teaching a robot to recognize a table tennis ball, right? If you only show it pictures of, you know, brand new, perfectly spherical balls, it might get confused if it encounters a slightly dented one. Oh, yeah, of course. Or a scuffed one in a real match. Right. It needs to be able to handle the real world, not just a perfect, idealized version. That's where domain randomization comes in. You deliberately introduce these variations into the simulation, like you were saying, right? So using balls with different levels of wear, maybe simulating different lighting conditions, even adding in a bit of virtual wind. Oh, wow. To make the robot more adaptable. So they threw everything they could at it, virtually speaking. Precisely. But even with all of that high-tech training, even with this ability to learn your weaknesses, this robot, it's not invincible. Let me guess. Every athlete has their weakness. Every athlete. Even a robot. Even a robot, exactly. Plus, this one's Achilles heel. You are absolutely right. And for this robot, it's the dreaded underspin. Underspin, really? Okay, what's so challenging about that for a robot? Well, so remember how the robot was trained on all of those thousands of ball trajectories? Right. Those mostly involved topspin, which is a much more common shot in table tennis. Okay. So when faced with that well-executed underspin, the robot really struggles. It's just not something it encountered as often in training. Exactly. So it's like finding that chink in the armor of this seemingly invincible machine. A well-placed underspin could be the key to victory. Nice. It just goes to show that, you know, strategy still trumps raw power, even in the world of robotics. That's awesome. Speaking of strategy, you know, this research didn't just train this robot to play table tennis in a vacuum. Right. They wanted to see how it would perform against actual humans. Of course, yeah. And not just any humans. 29 players with a range of skills. From beginners all the way up to what they called advanced plus. Basically table tennis wizards. You got it. They even brought in a professional table tennis coach to assess the skill level of each player and make sure, you know, everything was on the up and up. Talk about a high stakes game. So how did our robotic competitor fare against this gauntlet of human talent? Buckle up because this is where things get really, really interesting. So how did the robot do against those human players? Was it able to use its skills, its strategy, to outmaneuver them? You're not going to believe this. Okay. The robot actually won 45% of the matches overall. 45%? That's surprisingly good. Right? I mean, we've talked about its adaptive skills and everything. But to win almost half of its matches against humans, that's impressive. It really is impressive. And it gets even more interesting when you break it down by skill level. Okay. Against beginners, the robot was practically unbeatable. Oh, wow. Winning every single match. Okay. So it can dominate the newbies. Right. Makes sense. Beginners are still learning the ropes, figuring out their own strategies. But what about when it went up against more experienced players? That's where things get really interesting. The robot held its own against intermediate players, winning 55% of those matches. So more than half the time, it was beating players who have a pretty good grasp of the game. They've probably been playing for a while. That puts this robot solidly in the intermediate skill range itself. Yeah. I'm really curious about those advanced wizard-level players that you mentioned. Did it manage to pull out any wins against them? This is where we see the limits of its robotic abilities, at least for now. It didn't win any matches against the advanced players. Okay. However... So the top-tier players were able to outmaneuver, outsmart the machine. What were they doing differently? Well, even though it didn't win any matches against the advanced players, it still managed to win about 34% of the points. Okay. And that tells us something important. Even the best players had to work for those victories. Right. It wasn't a complete blowout. Exactly. I would love to know what kind of strategies those advanced players were using. Yeah. Did they figure out how to exploit the robot's weaknesses? They did. Remember how we talked about the robot's vulnerability to underspin? Right. The players who used a lot of underspin in their shots, especially targeting the robot's forehand, were much more likely to win. Interesting. So it's like, in any sport, you know, understanding your opponent's weaknesses and exploiting them is key to victory, even when your opponent is a robot. It's true. And that actually segues perfectly into another aspect of this research. Remember how we talked about how the robot learns and adapts to your game? Right. It turns out that learning process itself reveals a lot about the robot's strengths and limitations. Okay. I am intrigued. Tell me more about this learning process. So we've been talking about this robot learning your weaknesses, right? Like, as you play against it. But that learning process also kind of sheds light on the robot's own limitations. Okay

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
