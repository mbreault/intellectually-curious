# OEIS A000264 Hamiltonian Cycles in Cubic Maps

**Published:** June 30, 2025  
**Duration:** 16m 51s  
**Episode ID:** 17693034

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17693034-oeis-a000264-hamiltonian-cycles-in-cubic-maps)**

## Description

Learn about OEIS A000264 Hamiltonian Cycles in Cubic Maps

## Transcript

Welcome back to the Deep Dive. This is where we unpack complex ideas, find those really fascinating nuggets hidden inside. If you're someone who enjoys exploring the depths of mathematics, maybe you're deep into number theory right now, well this Deep Dive is definitely for you. We're continuing our journey through the amazing online encyclopedia of integer sequences, the OEIS. So our mission today is to crack open OEIS sequence A000264. Now I know that sounds like, well just a code, but it actually describes something really quite intricate. It's the number of three edge connected rooted cubic maps with two E nodes and a distinguished Hamiltonian cycle. Okay, that's a mouthful. Don't worry if those terms sound a bit much right now. Think of it this way. We're basically exploring how to count these incredibly robust, highly structured networks. Maybe like the backbone of a resilient communication system or even, you know, a complex molecular structure. And these networks have a unique efficient path running through them. Understanding this count, well it can offer some surprising insights. Maybe into network design or combinatorial properties or even just the fundamental nature of these mathematical objects. So let's unpack this. Precisely. And sequence A000264, it really is a beautiful meeting point for several key ideas in graph theory and combinatorics, which as you know have deep links to number theory, especially when you get into counting things, enumeration. What's really fascinating here is how it quantifies such a specific type of structure, these cubic maps, which crucially have this special kind of cycle running through them. So to really get it, we'll need to break down those terms, definitely. And we'll trace the history of these cycles is actually surprisingly long and uncover some of the big theorems that tell us when they even exist. Sounds like quite a journey. Okay, before we get into cubic maps or three edge connected, let's nail down the most basic piece for today. What exactly is a Hamiltonian cycle? What makes it special in graph theory? Right. So at its heart, a Hamiltonian cycle is a particular kind of closed loop inside a graph. You could imagine it like this. Say you're planning a grand tour of a city. You want to visit every single landmark, that's every vertex, in graph terms exactly once. And then this is the key bit, you want to end up right back where you started. That complete loop, hitting everything once, that's your Hamiltonian cycle. It's all about efficiency and complete coverage. And closely related, there's the Hamiltonian path. It also visits every vertex exactly once, but it doesn't necessarily loop back to the start. Ah, okay, so path versus cycle. Exactly. You can think of a path as maybe a cycle where you just took out one edge. And conversely, you can only turn a path into a cycle if its start and end points are directly connected by an edge. Now this concept, it sounds straightforward enough, right? But figuring out if these paths and cycles even exist in a given graph, especially a big one, well, that's incredibly complex. These are what mathematicians call NP-complete problems. NP-complete, right. For you listening, what does that really signify? Is it just a technical way of saying it's hard? It's definitely more than just hard. It means that for large graphs, even our fastest supercomputers would just grind away, potentially for centuries, trying to find a solution. You can't simply check every single possibility. It implies there's no known sufficient algorithm, no clever shortcut that can reliably find these cycles quickly for all possible graphs. And that challenge, that complexity, is exactly why theorems that guarantee their existence under certain conditions become so incredibly valuable. They tell us something is there, even if actually finding it is, well, computationally maybe out of reach. That's fascinating. Okay, so these cycles, they're named after the brilliant Irish mathematician William Rowan Hamilton. Can you tell us a bit about his contribution? How did the concept get his name? Absolutely. So William Rowan Hamilton, this was back in the mid-19th century, he really brought this whole idea into the limelight with his famous Icosian game, sometimes called Hamilton's Puzzle. And this game, it challenged people to find a Hamiltonian cycle along the edges of a dodecahedron, you know, that 12-sided solid shape. Right, the one with pentagon faces. That was the one. And he even developed his own algebraic system, the Icosian calculus, specifically to solve it. So his work definitely popularized the problem, gave it its name. So Hamilton really put them on the map, mathematically speaking. But was he actually the very first person to think about these kinds of paths? That's a great question. And it's a perfect example of how mathematical ideas often bubble up over time, sometimes in different places, different cultures. While the cycles carry Hamilton's name, the core idea, it actually predates him quite significantly. For instance, Thomas Kirkman, another mathematician, had already studied Hamiltonian cycles and polyhedra a year before Hamilton published his game. Kirkman even gave an example of a polyhedron that surprisingly didn't have one. Oh, interesting. So it wasn't a given that they always exist. Not at all. But the concept goes back even further, much, much further. Think about knight's tours on a chessboard. Ah, yes, where the knight has to hit every square. Exactly. That challenge, moving a knight to visit every square exactly once, that is precisely a Hamiltonian cycle or path problem on what we call the knight's graph. And we find records of people studying knight's tours way back in 9th century Indian mathematics with Rudrada and also in Islamic mathematics around the same time with Al-Adli Ar-Rumi. 9th century. Yeah. And then later in 18th century Europe, you had big names like Abraham de Moivre and Leonhard Euler also published some work on knight's tours. So these ideas, they've been around being pondered for, well, over a thousand years in some form. That history is just incredible. It really shows how these mathematical curiosities can persist. Okay, so moving from history to, let's say, the properties. Where do these Hamiltonian cycles typically show up in graph theory? What are some of their key characteristics? Well, it's actually quite remarkable how often they appear in different kinds of graph structures. For instance, take a complete graph. Where everything is connected to everything else. Exactly that. A network where every single point is directly linked to every other point. Any complete graph with more than two vertices, it's guaranteed to have a Hamiltonian cycle. Always. And of course, any simple cycle graph itself is Hamiltonian. I mean, it is a cycle. Makes sense. You also find them in those very regular, symmetric 3D shapes, the platonic solids. Think cubes, dodecahedra, tetrahedra. The graphs formed by their vertices and edges are all Hamiltonian. And beyond those, they pop up in more abstract structures too, like Cayley graphs, which are used to visualize algebraic groups. And something called the flip graph of convex polygons. Okay, so they're quite widespread in structured graphs. What about their fundamental properties? Are there rules that all Hamiltonian graphs have to follow? Yes, there are. One really key property is that all Hamiltonian graphs must be bi-connected. Bi-connected, meaning? It means the graph is robust enough that removing any single vertex won't disconnect it. You still have paths between all the remaining vertices. Think of it like a network that doesn't have a single point of failure. Okay, robustness. But does it work the other way? If a graph is bi-connected, does it have to be Hamiltonian? Ah, good question. No, it doesn't. The reverse isn't true. There are bi-connected graphs that don't have a Hamiltonian cycle. The classic textbook example is the Peterson graph. It's definitely bi-connected, but famously no Hamiltonian cycle. The Peterson graph. Right? I remember that one. It's a famous counterexample for a lot of things. Another interesting connection involves Eulerian graphs. Those are graphs where every vertex has an even degree, an even number of edges touching it. Okay. If a graph is Eulerian, then its line graph is guaranteed to be Hamiltonian. Now, the line graph is a kind of transformation. Where the edges become the points. Precisely. Each edge in the original graph becomes a vertex in the line graph. And two vertices in the line graph are connected if their corresponding edges shared an endpoint in the original graph. It's a neat transformation. And what's more, the line graph of any Hamiltonian graph, not just Eulerian ones, is also Hamiltonian. So there are these nice structural relationships. And can we actually count how many distinct Hamiltonian cycles a graph might have? Yes. For certain very structured graphs, we can get an exact count. For a complete undirected graph on n vertices, the number of distinct Hamiltonian cycles is n-1 divided by 2. Factorial. So that grows very fast. Extremely fast. And for a complete directed graph where the edges have arrows, basically on n vertices, the number is even higher. It's n-1. So the structure, and whether it's directed or not, really influences the count. Which leads us right back to that NP-completeness problem. If counting is hard and finding them is hard, how do mathematicians actually determine if a graph has a Hamiltonian cycle without just, you know, searching endlessly? Are there general rules? Theorems? Absolutely. And this is where graph theory gets really powerful. Instead of just brute force searching, mathematicians developed conditions, theorems, that guarantee a cycle exists if the graph meets certain criteria. One of the most powerful tools here is the Bondi-Shevaugh theorem from 1976. It works with something called the closure of a graph

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
