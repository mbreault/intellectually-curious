# AI Meeting Delegates: A Digital Teammate Attending for You

**Published:** February 18, 2025  
**Duration:** 13m 58s  
**Episode ID:** 17692596

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692596-ai-meeting-delegates-a-digital-teammate-attending-for-you)**

## Description

A deep dive into LLM-powered meeting delegates that can prep for, participate in, and even voice your contributions in meetings. We explain how the three-part system works (pre-brief, live engagement, voice synthesis), how researchers benchmark these agents with real transcripts and live demos, and what a three-phase deployment (execute, assist, deliberate) could mean for productivity, trust, and workplace dynamics.

## Transcript

Welcome back to our deep dive into the world of computer science. Today we're looking at something that seems like it's right out of science fiction, but it's actually getting closer to reality every day. We're talking about AI delegates for meetings. All those meetings you have to go to, some are super important, but others, well, maybe not so much. Yeah. What if you could send an AI to represent you in those meetings that you don't really have to be at? That's what researchers are looking into right now with these LLM-powered meeting delegates. Okay, so that sounds pretty cool. It is cool and kind of creepy when you think about how these systems are being designed to understand conversations and participate in them. They can even mimic your voice. Whoa, wait, using text-to-speech? Exactly. That's pretty wild. But how is that even possible? I mean, we're talking about AI that can understand how humans interact in a meeting. Well, the research paper that we're looking at today is called Meeting Delegate, Benchmarking LLMs on Attending Meetings on Our Behalf, and it lays out a framework for how to do just that. It focuses on the participant role in a meeting, which makes sense, you know, because most people attend way more meetings than they actually lead. Yeah, that's true. Right. So it's like having an AI teammate instead of an AI boss. Exactly. That's a great way to put it. So what does this AI teammate do during a meeting? Well, it has this three-part architecture. So first, it gathers information from you before the meeting even starts. Things like what topics you're interested in, any background knowledge you want to share, and materials you want it to bring up during the meeting. Okay, so it's kind of like giving your AI delegate a briefing before they go into the meeting. Exactly. So it's not just going in blind. What happens when the meeting actually starts? That's where the second part comes in. It's called meeting engagement. And basically, the AI analyzes the conversation as it's happening in real time. Oh, wow. It's looking for cues to understand when and how it should participate. Okay, so it's not just passively listening. It's trying to figure out how to actually contribute to the conversation. Exactly. It's like a human participant would, you know, trying to follow along and see when they can add something useful. Yeah, that makes sense. And then there's the voice generation part, right, where it can use text-to-speech to sound like you? Right. Okay, so all this is super cool, but how do we know that this AI delegate can actually do well in a real meeting? Right. Meetings can be pretty unpredictable. Oh, absolutely. And the researchers actually thought about that when they were designing this. Since there wasn't already a benchmark to measure how well an AI delegate could do, they decided to create one themselves. They did that by using real meeting transcripts. Oh, wow. So they're testing this AI on real-world data. That's amazing. So they're not just making up scenarios. They're using data from actual meetings. Exactly. That's really cool. How does this benchmark work? Well, they call their method the snapshot technique. And basically, imagine taking a snapshot of the conversation right after someone speaks, and then the AI delegate has to generate a response based on that snapshot. And then they compare that response to what actually happened next in the real meeting. Oh, I see. So they're testing its ability to adapt to the flow of conversation. Exactly. They designed different scenarios within that benchmark, like explicit cue where someone in the meeting actually directly addresses the AI delegate, and implicit cue where it has to kind of figure out on its own that it should chime in. Oh, wow. And you know what else they did? What? They simulated real-world transcription errors, too. Oh, that's clever, because meeting software isn't perfect. Exactly. It makes mistakes. Okay, so they thought of everything. Did they test this system with different types of AI models? They did, and they got some interesting results. Some of the models, like GPT-4, were pretty good at knowing when to participate and when to just stay silent. Others, like Gemini 1.5 Pro, were more cautious, while some of them, like Gemini 1.5 Flash and Llama 3, 8B70B, were a little too eager to jump in. Oh, so it's like different AI personalities are better suited for meetings than others. Yeah, it's kind of like humans. But overall, around 60% of the AI responses actually included at least one key point from the real follow-up conversation. Yeah. That's actually pretty impressive. It is impressive. Okay, so they were listening and responding to a transcript, but how did the AI actually do in a live meeting? Well, they did a scrum meeting demo with human participants, and the AI delegate was powered by GPT 3.5 Turbo, GPT 4, and GPT 4.0. Did the humans know they were talking to an AI? Well, GPT 3.5 Turbo struggled a bit, but GPT 4 and GPT 4.0 did better, although they had some issues with repetition and latency. It seems like even the most advanced AI models still have a bit of trouble keeping up with a live conversation. Yeah, that makes sense. Keeping up with a live conversation is definitely harder than analyzing a transcript. But all this seems super experimental, so how would we actually use these AI delegates in the real world? Well, the researchers have a three-phase deployment plan where the AI gets more autonomy in each phase. The first phase is called execute, and it's basically like a super-controlled AI delegate. It only shares information that you've already approved. It collects data based on your instructions, and it doesn't make any decisions on its own. So it's like a super-powered note-taker. Yes, exactly. The focus in this phase is on minimizing risk and making sure the AI is only operating within the boundaries that you set. But the plan is to eventually move toward giving the AI more autonomy. Okay, I'm curious now. What do those later phases look like? Phase two is called assist, and this is where the AI delegate gets more decision-making power. It can analyze sensitive data, of course following strict privacy guidelines, and it can even start suggesting actions based on the data. Oh, wow. But the users still have the final say in this phase. So it's more like an AI advisor now, not just a note-taker. Exactly. That seems like a pretty big jump from phase one. It is a big jump, and that's why the researchers are really emphasizing this gradual rollout. You know, they want to make sure that these systems are reliable and trustworthy before giving them more freedom. That makes a lot of sense. So what about the final phase? Is that where the AI gets to make all the decisions? Yeah, that's the idea behind phase three, Delafit. In this phase, the AI can actually collect and share information on its own, make real-time decisions based on your goals, and it can even negotiate on your behalf. Wow, that's a lot of responsibility for an AI. It's almost like having a digital twin representing you in those meetings. It is kind of like that, but the researchers are very clear that even in this fully autonomous phase, the AI delegate should always operate within the ethical guidelines and boundaries that you set. Yeah, that makes sense. You mentioned earlier that the researchers built a scrum meeting demo to test out this AI delegate. Can you tell me more about what that involved? Sure. They had human participants interact with an AI delegate, and the AI was powered by different LLM models like GPT 3.5, Turbo GPT 4, and GPT 4.0. This allowed them to see how the AI would interact with real people in a live setting. That's really interesting. So what did they learn from this real-world testing? Well, they found that some models performed better than others. For example, GPT 3.5 Turbo had some trouble keeping up with the conversation, while GPT 4 and GPT 4.0 did a better job, although they did have some issues with repetition and there were slight delays in their responses sometimes. Oh, so there are still some things to work out, even with the most advanced AI models. Right. But even with those challenges, the idea of having an AI delegate is really intriguing. It is. Imagine skipping all those meetings that you don't really need to be at and using that time to do something else. Yeah, you could have your AI delegate attending those routine status updates while you focus on more strategic work. That would be a huge productivity boost. But I also wonder about the impact on team dynamics. Would people feel comfortable sharing information with an AI delegate? Yeah, that's a good point. As with any new technology, there's going to be a period of adjustment. People will need to develop trust in these AI systems before they feel completely comfortable sharing sensitive information. Yeah, trust is really important, especially when you're talking about AI having access to confidential data. So how are the researchers addressing this issue of trust? They're focusing on transparency. They're working on ways to make these AI systems more understandable to humans. Okay. This involves things like providing clear explanations of how the AI works, giving users control over what information the AI can access, and making sure the AI's decisions are traceable and explainable. So it's not just about building a powerful AI. It's also about building an AI that people can understand and trust. Exactly. And that trust is going to be built over time as people gain experience interacting with these AI delegates and see firsthand how they can be beneficial. Yeah, I could definitely see the potential here, but I also wonder about the potential downsides. Like what about the risk of job displacement? If AIs are attending meetings for us, does that mean human jobs are at stake? That's a common

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
