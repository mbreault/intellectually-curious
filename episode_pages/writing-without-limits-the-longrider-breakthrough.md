# Writing Without Limits: The Longrider Breakthrough

**Published:** October 13, 2024  
**Duration:** 8m 41s  
**Episode ID:** 17692631

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692631-writing-without-limits-the-longrider-breakthrough)**

## Description

In this episode we unpack Longrider and the move to long-form AI writing: why current models stall at a few thousand words, how training data length matters, and how AgentWrite's planning-plus-writing pipeline pushes outputs to 10,000+ words. We discuss LongWriter data sets, LongBenchWrite benchmarks, ablation tests, and what this means for the future of AI-assisted storytelling and work documentsâ€”along with the limits and open questions that still loom.

## Transcript

Ever get stuck writing something? Like a report for work? Or even something fun like a short story? You have more to say, but the words just dry up. Happens to the best of us. Right. Now imagine that, but it's happening to an AI. That's the issue researchers are hitting with these large language models. It's a weird limit that's been throwing people off. Yeah, it doesn't make a lot of sense on the surface. Because these AI models, or LLMs, can read tons of words. Hundreds of thousands, easy. So why can't they write that much? That's what we're getting into today. We've got this new research, Longrider, unleashing 10,000 plus word generation from long context LLMs. It's a mouthful. It is. But it really gets into why these AI hit a wall. A really important finding was this. How much these AIs were trained on directly affects how much they can output. So it's not that they forget or run out of steam. Not at all. It's like, say, learning to cook. If you've only ever learned to make appetizers. Right. You'd be great at those small dishes, but ask for a four-course meal. You'd be lost. Exactly. These LLMs, they've been trained on appetizers, not feasts. Okay, that actually makes a lot of sense. Explains why that 2,000 word limit is so common. Right. Because a lot of the training data is from existing AI, which also hits that limit. Vicious cycle of short writing. But this team, they didn't just point out the problem, they came up with a solution. AgentWrite? Okay, intriguing. It actually mirrors how we write. Really? Instead of saying write a whole book, which, by the way, it's not quite ready to do yet. Right, right. AgentWrite breaks it down. So like chapters, outlines, word counts, that kind of thing. Exactly. Two stages. Planning, that's the outline part. Then writing where the LLM tackles each section. And get this, using AgentWrite, they got GPT-4o to output 20,000 words. Whoa, 10 times the usual. But were those extra words any good? That's the impressive part. They made a new benchmark. LongBenchWrite, tons of different writing tasks. Okay. And even at those lengths, the writing was good, it made sense. So they basically gave these AIs some serious writing stamina. And they didn't even stop there. They made a whole data set with AgentWrite. LongRider 6K, that's new, right? Brand new. Cutting edge stuff. And it's full of examples of longer, more complex writing. They used it to train models like GLM 4.9B and Llama 3.18B. Guess what? Hitting 10,000 words. Consistently. That's novella length. Are they training AI to write books now? It's remarkable progress for sure. But they didn't just want to trust what they saw. They had to prove it wasn't a fluke. So they did a bunch of tests, including something called the cumulative average negative log likelihood test. Okay, that's a mouthful. It is. But basically it showed that the AI wasn't just putting random sentences together. It was understanding the connections between ideas. So learning to write not just longer, but smarter. Exactly. That's incredible. Have they cracked the code on longer AI writing? It's not quite that simple. There are still challenges, but this is huge. So we've seen these big jumps in how much AI can write. Yeah. But how did they get these results? They didn't just luck out, did they? No, no. They were really careful with their testing. They wanted to make sure these findings were legit. Like they did this thing called an ablation study. Ablation study. Is that where they're like dissecting something? Like a frog in biology? Well, not a frog. Right. But you're getting the idea. They basically take out or change parts of the training to see what happens. Like figuring out which ingredients actually matter in a recipe. Exactly. Did they find the secret ingredient for longer AI writing? Seems like this long writer 6K data set is key. When they took it out completely, just trained the AI on the usual short stuff, it went right back to that 2,000 word wall. So it really was seeing those long examples that made the difference. It's a big deal. What I find interesting is they didn't just give the AI finished stories, right? They included the planning too. The chapter outlines from AgentRight. Right. Were they hoping the AI would learn to plan better by seeing examples? That was the idea. But surprisingly, it didn't really improve the results that much. Huh. So they gave it the answers to the test, but it was already figuring them out on its own. That's a great way to put it. It shows how these LLMs learn in ways we don't totally get yet. Right. Sometimes giving them more instructions isn't the answer. It's about the data. It's about exposure to the right stuff, letting them figure out their own way. That's exciting, but also kind of spooky, right? This whole AI learning thing is such a black box still. For sure. Speaking of learning, they tried something else that didn't work as well. Instruction back translation. Right. It's worked in other AI stuff. Yeah. Not so much for long writing. Why not? The idea seems smart. Take long texts and have the AI figure out the instructions that would make them. Yeah, in theory. But the problem was the quality of those long texts wasn't always great. And the instructions the AI came up with didn't really reflect how a human would do it. So it's like trying to learn to write a symphony by analyzing elevator music. The source material just isn't there. Exactly. So you need the good stuff. You need those good outputs, realistic instructions in the training data for it to work. And that's where Longrider 6K is different. It's got those well-written, long examples closer to what we humans actually create. That seems to be the key. It's true, though, right? AI is only as good as what it learns from. Absolutely. But even with these breakthroughs, I'm guessing there are still limits, especially with something as complex as writing. Oh, for sure. This is a big step, but longer writing has its own challenges, like just processing all that text. That takes time, resources. Right, because no one wants to wait hours for the AI to finish a sentence. Exactly. And then the bigger question, can these longer outputs really capture what makes human writing so good? The nuance, the depth. Can AI get character development, emotional arcs, all that? Million dollar questions right there. Can AI actually be creative? It's something researchers are working on right now. We're still in the early stages, especially with creative writing. Yeah, this isn't about replacing authors anytime soon. Yeah. But it does make you wonder, what's possible? What stories we could tell? Absolutely. But before we get too ahead of ourselves, let's go back to some specifics about the long writer research itself. They were really thorough, and I think it's worth highlighting a few things they did. One thing I really like was how open they were about everything they did. They didn't just say, hey, we trained an AI, got amazing results. They showed their work. It's good to see that, especially in a field that can be, you know, kind of vague sometimes. For sure. Like they could have skipped the tech stuff, but they were really specific about the models they used, like GLM 4.9B and Llama 3.18B. And then they made their own, long writer 8B, long writer 9B. And even then, they went further. They fine-tuned one, made long writer 9B DPO. Like the student who gets extra credit. They used something called direct preference optimization. DPO? Yeah. Basically like giving the AI a writing coach. So it's not just writing more, it's writing better. Exactly. And it worked really well. This fine-tuned model, even though it wasn't the biggest, it was right up there with GPT-4o in terms of quality. And sometimes even better at following instructions, especially for the longer stuff. That's amazing. Sounds like they've opened up a ton of possibilities. It's exciting. But like you said before, still early days. What are the big challenges left for pushing these models even further? Well, one of the biggest is just the computing power. All that text, it takes a lot of power and time. Imagine writing a novel on like a computer from the 80s. Oh, it'd take forever. Exactly. And that's with the AI already knowing what to write. Then there's the even bigger question. Okay. Can AI ever truly be creative like humans? Can it get those nuances, the emotional stuff, the surprise of human imagination? Those are the questions that keep me up at night. Right. It's exciting and a little scary. It really is. Right. But I guess AI doesn't have to replace human creativity. It could work with it, enhance it. Collaborate. Who knows what we could create together? Maybe someday we'll look back at those 2,000 word limits and laugh. I think that day might come sooner than we think. Well, I think that's about all the time we have for this deep dive. It's been quite a journey into AI and writing. It has. It really shows how fast things are changing. Absolutely. If you're anything like me, your mind is probably racing with possibilities. So until next time, keep exploring, keep asking questions, and keep an eye on the future, because the future of storytelling is being written right now.

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
