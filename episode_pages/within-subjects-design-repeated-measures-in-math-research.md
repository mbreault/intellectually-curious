# Within-Subjects Design: Repeated Measures in Math Research

**Published:** April 22, 2025  
**Duration:** 11m 56s  
**Episode ID:** 17693428

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17693428-within-subjects-design-repeated-measures-in-math-research)**

## Description

A clear, practical tour of within-subjects designâ€”where the same participants experience all conditions or are measured repeatedly over time. We explore the core idea, key advantages like controlling individual differences and higher statistical power, the main challenges such as carryover effects and how counterbalancing helps, and the analytical toolsâ€”repeated measures ANOVA and linear mixed modelsâ€”that make this design powerful for math education and longitudinal studies.

## Transcript

Welcome to this deep dive. Today we're looking at a really fundamental concept in mathematical experimental design, the within subjects design. That's right. It's a core method, sometimes called repeated measures or even longitudinal design. Super important for understanding how things change. Okay, great. So for anyone new to this, what exactly is a within subjects design? What's the main idea we need to grasp? Well, the core idea really is that you're examining the same group of participants under different conditions. Or maybe you're measuring them multiple times over a period. The same participants. Okay. Yeah. So imagine you're testing how different, say, mathematical software interfaces affect problem solving speed. Right. In within subjects design, you'd have the same individuals try out each of those interfaces. Ah, I see. So it's not like group A gets interface one and a totally different group B gets interface two. Exactly. That second scenario, that's a between subjects design. Here, the comparison is happening within each individual because they experience all the conditions. Okay, that makes sense. And you mentioned measuring over time as well. So it's not just for active experiments with different conditions we impose. Precisely. You could experimentally test different teaching methods for a tricky calculus concept on the same students, but you could also use it observationally. Like? Like tracking how a student's grasp of geometric proofs develops over, say, a whole school year. That's a classic longitudinal study, a type of within subjects design where time itself is the key variable. Got it. So, okay, why go this route? What are the big advantages of using a within subjects approach, maybe particularly in a mathematical context? Well, probably the biggest advantage is the control you get over individual differences. Think about it. The same people are in every condition. Right. So their baseline mathematical ability, their motivation, their background, all that stays constant across the conditions because it's the same person. Exactly. If you're testing, say, a new method for teaching fractions, you don't have to worry that one group was just naturally better at math to begin with. That person serves as their own control. That seems powerful. It is. And it leads directly to another huge benefit, increased statistical power. Meaning? Meaning you're more likely to actually detect an effect if one truly exists compared to a between subjects study with the same number of participants. Why is that? Because you're removing the noise caused by those inherent differences between people. Each participant acts as their own baseline, their own benchmark. So the effect of your manipulation, like the teaching method or the interface, stands out more clearly. Okay, so if I'm studying maybe how different types of feedback impact students' ability to spot errors in logical arguments, I might need fewer students overall to see if one type of feedback really works better. Precisely. You often need fewer participants to achieve the same level of statistical power, which is, you know, a big practical advantage in research. Saves time, resources. Yeah, definitely. Are there other upsides? Sure. They're great for tracking subtle changes over time, as we mentioned with longitudinal studies. Think about monitoring progress and understanding a complex mathematical theory. And some argue that by having the same person experience all conditions, you get a conceptually cleaner look at cause and effect, almost observing the counterfactual for that individual. Plus, sometimes repeated measurements can lead to more stable data overall. Okay, these are pretty compelling reasons, but nothing's perfect, right? What are the catches? The potential problems? Yeah, the main challenge revolves around something called carryover effects. Carryover effects? Basically, because participants go through the conditions one after another, the experience of being in an earlier condition can sort of bleed over and affect how they perform in a later one. So it's not like hitting a reset button between each condition? Not always, no. One type is just a general order effect, the sequence itself matters. But more specifically, you can have things like practice effects. Ah, so if you're doing several types of math problems, you might just get better at doing that kind of problem as you go along, regardless of the specific conditions. Exactly, or the opposite fatigue or boredom effects. Performance might drop off simply because the session is long. Okay. What else falls under carryover? Well, there are context effects. Being exposed to one condition might change how you perceive or react to the next one. Imagine judging mathematical proofs for elegance. Seeing a truly messy one first might make an average one seem better than it is, or vice versa. Hmm, interesting. And there's also the possibility that participants, because they see all the conditions, might figure out the study's hypothesis and consciously or unconsciously change their behavior. Right. So all these carryover things, they can mess up the results, make it look like your condition had an effect when it was really just practice or fatigue or something else. Precisely. They can confound your independent variable, the thing you're actually trying to test. It clouds the picture and can really threaten the internal validity of your conclusions. You might be measuring the carryover, not the treatment effect. Yikes. Okay, so how do researchers handle this? Can these effects be managed? Yes, thankfully. The primary tool is called counterbalancing. Counterbalancing. The idea is simple. You test different participants in different orders. So if you have condition A, say traditional teaching method, and condition B, new method, half your participants get A, then B, and the other half get B, then A. Okay. And if you have more conditions, like A, B, and C? Then you need more orders. With three conditions, there are actually six possible orders. ABC, ACB, BAC, BCA, CBA. You try to assign participants evenly across these different sequences. And the goal of doing all that is? The goal is to spread any potential carryover effects evenly across all the conditions. So if there is a practice effect, hopefully it boosts performance in condition A just as much on average as it boosts performance in B and C. Sort of washes out in the overall comparison. Makes sense. Spread the air around. Exactly. Another approach is simply to randomize the order of conditions for each participant individually. Or if you have enough people, you can actually make the order itself a variable in your analysis to see how big the carryover effect really is. But that sounds like it adds a layer of complexity to the whole thing. Oh, it definitely can. Counterbalancing isn't always simple to implement, especially with many conditions. And crucially, sometimes carryover effects are just too strong or inherent to the task. Like what? Well, imagine one condition involves teaching participants a fundamentally new, very effective technique for solving a certain type of equation. Once they learn it, they can't really unlearn it for the next condition, even if it's supposed to be a control condition without that technique. Ah, okay. The cat's out of the bag, so to speak. Right. In those situations where the effect of one condition is largely irreversible or creates unavoidable carryover, a within-subjects design might just not be the best choice. You might need a between-subjects design instead. Understood. So, assuming we can manage carryover, how do we actually analyze the data we collect? You mentioned the statistical power. Does the analysis differ from between-subjects? It absolutely does. Because you have multiple data points from the same person. Those data points aren't independent. They're likely correlated. Standard techniques like a regular ANOVA or an independent t-test aren't appropriate. So, what do we use? A very common technique is called repeated measures ANOVA. Think of it as an extension of the paired samples t-test, which you'd use for just two related measurements, like a before and after score. Repeated measures ANOVA handles situations with three or more conditions or time points. Okay, still ANOVA, but repeated measures. How does it work differently? Well, like all ANOVAs, it breaks down the total variability in the scores. But the key thing here is that repeated measures ANOVA specifically accounts for the variability between participants. It essentially removes that individual difference component from the error term in the analysis. And that's what boosts the power. By reducing the error, you're comparing the treatment effect against. Exactly. You're isolating the effect of your conditions more effectively by statistically controlling for the fact that some people just generally score higher or lower than others. And the main question it answers is still, did our conditions have a significant effect overall? Yes, the overall F-test tells you if there's any significant difference among the condition means. If that's significant, you then need to do follow-up tests, often called post-hoc tests, maybe like adjusted paired t-tests to figure out which specific conditions differ from each other. Right. There are also some specific statistical assumptions to check, like sphericity, which basically relates to the variances of the differences between conditions. If that's violated, you might need to apply corrections. Okay. Any other analysis approaches? Yes, increasingly, especially with better software. Researchers are using linear mixed effects models. They're generally more flexible than traditional repeated measures or ANOVA. They can handle missing data better and model the correlations between repeated measurements more explicitly. They're quite powerful. Interesting. And bring it back to those longitudinal studies, tracking mathematical development over time. This design seems tailor-made. Absolutely. When your research question is inherently about change within individuals over time, like how does mathematically reasoning develop across childhood? Or what's the long-term impact of an educational program? A within-subjects or longitudinal approach is often the most natural and informative way to go. Time itself becomes your independent variable. It really lets you see that individual trajectory. Precisely. Okay, so let's try and synthesize this. When should a researcher studying something mathematical really lean towards using a within-subjects design? Well, it's a strong contender when controlling for those individual differences is paramount. If you know there's huge variability between

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
