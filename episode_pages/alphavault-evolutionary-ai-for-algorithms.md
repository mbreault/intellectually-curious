# AlphaVault: Evolutionary AI for Algorithms

**Published:** May 15, 2025  
**Duration:** 10m 59s  
**Episode ID:** 17692162

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692162-alphavault-evolutionary-ai-for-algorithms)**

## Description

A Science Corner deep dive into AlphaVault, Google's Gemini-based coding agent that discovers and optimizes algorithms through an evolutionary loop. We explore how broad idea generation meets rigorous evaluation, plus real-world wins from Borg scheduling, TPU design, and faster model trainingâ€”alongside breakthroughs in math. Where is this headed next, and why does it matter?

## Transcript

Welcome back to Science Corner. This is our space for, you know, getting into the details for those of you curious about the big ideas changing things. Glad to be diving in. Today we're looking at something called AlphaVault. It's a new coding agent powered by Google's Gemini models. Quite interesting stuff. It really is. We're seeing these large language models branch out. You know, not just text, not just generating code snippets anymore. Right. They're starting to tackle fundamental scientific problems, computational challenges. It feels like a real step change. AI discovering and refining algorithms. Absolutely. And evolution, like you said. And AlphaVault seems to be right at the cutting edge. So our plan today is to unpack how it works and look at some, well, frankly, impressive results they're already seeing. Sounds good. Okay, so let's start right there. What is AlphaVault fundamentally? Right. So AlphaVault at its core is an evolutionary coding agent. Its job is algorithm discovery, algorithm optimization. And the real innovation, I think, is how it pairs things up. It takes the creative side of the Gemini models, their ability to come up with ideas, and combines that with automated evaluation systems, rigorous testing, and wraps it all in an evolutionary framework so it keeps improving generation after generation. Interesting. So it's not just one single Gemini model doing everything. No, exactly. It's smarter than that. It uses an ensemble. Think of it like Gemini Flash, which is fast. It throws out a whole lot of ideas, explores broadly. It's casting a wide net. Precisely. And then Gemini Pro, which is more powerful, dives deeper into the promising leads, refining them. Okay, that makes sense. Breadth, then depth. So how does that cycle actually work, the improvement loop? Well, it starts with generating prompts. Basically, specific instructions or questions for the Gemini models. Guiding them. Right. To get them to generate programs, actual code, that represent potential solutions. Then these programs hit the automated evaluation stage. Testing them out. Exactly. Against predefined metrics. How accurate are they? How good? And then finally, the evolutionary algorithm steps in. Ah, the evolve part. Yes. It selects the best performers from that generation, the programs that scored well, and the successful ones. They influence the next round of program creation. Like natural selection for code. Kind of, yeah. The most effective code survives and helps breed the next, hopefully better, generation. Fascinating. So it's this loop. Generate, test, select, repeat. Okay. Now, the source material mentions some really big applications inside Google's own systems. Let's talk data centers. Borg scheduling. Yes, that's a really powerful example of its practical use. AlphaVault actually discovered a heuristic, a kind of rule of thumb for Borg. Borg being Google's big data center manager. Exactly. Orchestrates everything. And this heuristic, it sounds simple, but it's been running in production for over a year now. And the impact. It consistently recovers, on average, about 0.7% of Google's compute resources worldwide. Hold on. 0.7%. Now, that might sound small to some, but at Google scale, that must be absolutely massive. It is. It's a colossal amount of computing power saved, or rather, made available for other work. It really shows how AI can find these efficiencies in incredibly complex systems that humans might just miss. Yeah, totally hidden optimizations. And what's also key here is that the code AlphaVault generated was human-readable. Oh, that's important. Hugely important for operations. It means engineers can understand why Borg is making certain decisions. That gives you interpretability. Right. And it makes it easier to debug, makes the system more predictable, simplifies actually deploying the changes. Big practical wins. That human-readable aspect feels critical for bridging the gap, doesn't it? Between the AI finding a solution and engineers actually trusting and using it. Okay, what about hardware design? That seems like a very different domain. It is, and it shows the versatility. AlphaVault contributed to designing Google's TPUs, their custom AI chips. Tensor processing units, right? Yes. Specifically, it looked at a highly optimized circuit for matrix multiplication, a core operation. AlphaVault suggested a change to the Verilog code. The hardware description language. Right. It basically said, you can remove these specific bits here. They aren't necessary. Wow. Okay, removing bits from a chip design sounds risky. How do you ensure it doesn't break anything? Oh, absolutely. That's paramount. Any change like this, especially suggested by an AI, has to go through incredibly rigorous verification. Exhaustive tests. To guarantee it still works correctly. Completely. Functional correctness is non-negotiable. The fact that AlphaVault's suggestion passed all those tests and is actually being integrated into a future TPU, well, it points to a really interesting future for AI collaborating with hardware engineers. A real synergy there. Okay, shifting gears again, let's talk about AI itself. How is AlphaVault helping train and run models like, well, like Gemini, the model that powers it? Yeah, it's a bit meta, isn't it? AlphaVault improving its own kind. It found better ways to break down large matrix multiplications. Which are fundamental for training these huge models. Absolutely essential. By optimizing a key computational part, a kernel within Gemini's architecture, AlphaVault sped it up by 23%. 23% faster kernel. Okay. And that, in turn, shaved off about 1% of the total training time for Gemini. Again, 1% sounds small, but for training massive models, that's huge savings in time and compute costs. Exactly. The leverage is enormous. And think about the engineering time, too. This kind of deep kernel optimization usually takes highly specialized engineers weeks, maybe longer. AlphaVault could explore and find these improvements in days. Weeks down to days. That's a serious acceleration for development. Huge acceleration. And it didn't stop there. It even went deeper. Deeper how? It looked at optimizing low-level GPU instructions, the stuff that runs directly on the graphics cards. Wow. That's usually compiler territory, isn't it? Heavily optimized already. Extremely optimized. Humans rarely tweak things at that level directly. But AlphaVault managed to find speedups up to 32.5% for the flash attention kernel. Flash attention. Crucial for large language models, helps them handle long inputs efficiently. That's the one. Getting that kind of speed up there is incredibly valuable. It helps the human experts pinpoint subtle bottlenecks, maybe things they hadn't seen. And they can just take these AI-found improvements and integrate them. Pretty much. Integrate them into their code bases. So you get immediate performance gains, potentially energy savings too, and maybe even ideas for future optimizations. These internal Google examples are really compelling. You see the concrete benefits. But AlphaVault isn't just about optimization, right? It's also pushing into more fundamental discovery, mathematics, new algorithms. That's absolutely right. It's shown this quite remarkable knack for tackling complex mathematical problems, sometimes starting with very little guidance, just minimal code. Okay. They applied it to over 50 open problems in different areas of math. And in about three quarters of those cases, it rediscovered the state-of-the-art solutions, the best known answers. Wow. 75% rediscovery rate. That's impressive validation. But did it ever go beyond just finding what we already knew? It did. In roughly 20% of those problems, it actually improved on the best known solutions. Yeah. Made real progress on these longstanding mathematical challenges. Okay, like what? Any specific examples? Yes. Take matrix multiplication again, but for complex numbers, 4x4 matrices. For decades, Strassen's algorithm from 1969 was kind of the benchmark. Right. AlphaVault found a new algorithm that does it using only 48 scalar multiplications. That's better than Strassen's for this specific case. A genuine improvement on a foundational problem. Improving on Strassen's algorithm. That's significant. I also read something about the kissing number problem. Sounds fun, but what is it? Okay, yeah. It's a classic geometry problem. Basically asks, how many identical spheres can you arrange so they all touch a central sphere of the same size without overlapping? Okay, like billiard balls around a central one? Exactly. But in higher dimensions. AlphaVault tackled this for 11 dimensions. 11 dimensions, okay. And it discovered a new configuration. It found a way to pack 593 outer spheres touching the central one. This set a new lower bound for the kissing number in 11D. A real contribution to pure mathematics. So it's finding faster ways and finding fundamentally new arrangements or solutions. You mentioned AlphaTensor earlier briefly. How is AlphaVault different? Good question. AlphaTensor was, well, tensor-focused. Primarily designed for finding efficient matrix multiplication algorithms. Right, more specific. Yeah. AlphaVault is broader. It builds on those ideas, sure. But its evolutionary approach using the Gemini ensemble, it makes it much more general purpose. It can tackle a wider range of algorithmic discovery and optimization tests. Not just matrix math. A more versatile tool. Okay, this all sounds incredibly powerful. Where does it go from here? What's the path forward for AlphaVault? Well, the trajectory seems clear, right? It's moving from optimizing specific things like code inside Google towards these harder, more complex real-world problems. Across different fields. Exactly. And as the underlying LLMs like Gemini get even better at understanding and generating code, you'd expect AlphaVault's abilities to grow too. Makes sense. Plus, they're working on making it more accessible. Building a user-friendly interface, planning an early access program for academic researchers. Getting it into more hands. Which is vital, really, to see what happens when more people can explore and apply it. And the potential applications seem vast. Beyond computing and math. Oh, absolutely.

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
