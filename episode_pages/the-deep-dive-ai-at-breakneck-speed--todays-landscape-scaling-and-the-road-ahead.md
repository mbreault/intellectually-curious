# The Deep Dive: AI at Breakneck Speed â€” Todayâ€™s Landscape, Scaling, and the Road Ahead

**Published:** May 31, 2025  
**Duration:** 18m 46s  
**Episode ID:** 17692131

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692131-the-deep-dive-ai-at-breakneck-speed-â€”-todayâ€™s-landscape-scaling-and-the-road-ahead)**

## Description

We cut through the noise to map where AI stands now: consumer adoption, enterprise deployment, and the growing influence in science, media, and government. We unpack accelerating capabilitiesâ€”from cognitive automation and agentic AI to multi-step workflowsâ€”plus the infrastructure engine behind it: data centers, chips, and the economics of training vs inference. Finally, we look ahead to what might come next and how fast change could accelerate.

## Transcript

Welcome to The Deep Dive. Today, we're jumping into something that, well, it feels like it's moving faster than most of us can really keep up with. The world of AI. Specifically, we want to do a deep dive into where it stands today. You know, its applications, how it's scaling, and then look at what the road ahead might look like tomorrow. Yeah, and that feeling of speed, it's palpable. It really comes through in the sources we've gathered for this. We've got a whole collection of recent reports, some really eye-opening data points, commentary from industry folks, observations on how people are actually using this stuff, and importantly, a look at the sheer scale of the infrastructure being built. Right. So our mission here, for you listening, is to try and cut through some of that noise, pull out the most important facts, the key trends. We want to unpack what's really happening with AI right now, get a sense of its applications, understand this, frankly, dizzying pace of scaling, and look at where it seems to be heading. It's definitely one of those topics where fast-moving just feels like a massive understatement. I mean, these sources really suggest the pace of change we're seeing now is, well, among the fastest periods of technology compounding humanity's ever really experienced. Okay, let's anchor that speed then. What are people calling AI's iPhone moment? When did this massive acceleration really hit the sort of broader public consciousness? Well, that moment is pretty much pinned to the public launch of generative AI. Specifically, ChatGPT back in November 2022. Suddenly, AI wasn't just this abstract thing or, you know, tech working behind the scenes. It became a tool that anyone could use directly to create things, text, images, audio, even code. And the reaction from users was just immediate. Yeah, huge, right? Unlike anything before. Oh, totally unprecedented. ChatGPT saw the fastest user ramp up for standalone product ever. Think about it. One million users in just five days. And to give that some scale, the sources point out ChatGPT hit 355 billion annual searches in only two years by 2024. Google. It took them 11 years to reach that same volume back in 2009. That comparison alone, it tells you something pretty dramatic about the acceleration. Wow, okay. 11 years versus two. Yeah. Yeah, that's staggering. And it wasn't just people signing up initially, right? They're actually spending more time with it. Exactly. The data shows engagement is getting deeper. Daily time spent on the ChatGPT app just in the USA jumped by, get this, 202% over about 21 months. That's from July 2023 to April 2025. So yeah, people are really integrating it. Okay, so massive adoption in these direct consumer tools. How else is AI starting to impact, say, the creation and distribution of content, knowledge, that kind of thing? Well, we're definitely seeing its fingerprints in places like academic research. For example, one analysis found that about 1% of scientific papers published in 2023 showed some kind of generative AI involvement. You know, top journals are already scrambling to issue guidance on how researchers need to disclose using these tools. And news and media, too, I imagine. That seems like a primary. Oh, heavily. By mid-2024, sources estimated something like 6.96% of global news articles daily were AI generated. And if you look back just a bit, May 2023, there were already over 1,200 news and info websites identified that were relying mostly on AI content, often with, like, minimal human checking. Even the big players, like the Associated Press, they were automating around 40,000 stories by mid-2023. That was about 5.5% of their total output. So, yeah, it's not niche. It's hitting the mainstream information flow. That covers the digital side quite starkly. But AI isn't just staying on our screens, is it? We're seeing it pop up in the physical world, too. Exactly right. Take autonomous taxis, for instance. According to data from April 2025, they're rapidly grabbing market share in big cities, like San Francisco. That's AI making real-time decisions, operating directly in our messy physical world, moving people around. So beyond these specific examples, how are the sources talking about AI's impact on something more fundamental, like work itself, across different sectors? Yeah, it's evolving incredibly fast there. We're seeing what they call cognitive automation AI systems that can reason, create, solve problems, really taking off alongside the physical automation we already know, like robots and drones. But what's truly astonishing, based on these sources, is the speed of improvement in that cognitive ability. In just the roughly three years since ChatGPT went public, the sources suggest AI has leapt from maybe like a high school student level of reasoning to something getting pretty close to near human level reasoning. Near human level reasoning in three years? That's almost hard to grasp. That kind of acceleration is mind-bending. How's that actually showing up in, say, the business world, in enterprise? Well, companies are definitely seeing real results already. There's an example gleaned. They do enterprise search and AI agent stuff. Their annualized revenue apparently grew 10 times, hitting $100 million in just two years. That points to this shift towards horizontal platforms. The value isn't just in selling software licenses anymore. It's shifting towards charging for the embedded intelligence, the AI-driven outcomes across different business functions. Ah, okay. So it's less about buying a specific tool and more like buying a smart capability that plugs into your workflow. Precisely, yeah. Think about AI agents that can automatically summarize, I don't know, all your internal meeting notes or handle complex customer support issues from start to finish. That intelligence is getting woven right into how businesses operate. And it's not just the private sector feeling this. Government, education, they must be grappling with this too. Oh, absolutely. Adoption is becoming a much higher priority there as well. The sources mentioned things like OpenAI launching ChatGPT Gov specifically for government use. And you see major universities partnering up. University of Michigan, Oxford, both announced collaborations with OpenAI in March 2025. Arizona State launched a whole AI acceleration organization back in August 2023. Institutions are actively trying to figure out how to use this and, you know, manage it. It sounds like AI is also moving beyond just like answering simple questions to actually performing more complex multi-step kinds of tasks. Yeah, that's the shift towards what people are calling agentic AI. It's moving into automating more specialized knowledge work. Google's Gemini, for instance, has this feature called deep research. Apparently it can browse hundreds of websites, analyze what it finds, and then create these comprehensive reports. That's AI acting more like a research assistant, you know? Sure. An agent taking on complex workflows, not just giving a quick answer. Okay, that gives us a really good picture of the now, the applications we're seeing. But none of this massive growth happens in a vacuum. What about the underlying physical demands, the engine room, as the sources called it? What's needed to power this kind of speed? Right, and this ties straight back to that idea of accelerating technology compounding we mentioned earlier. This level of growth needs just immense infrastructure. And running these really advanced AI models sounds incredibly expensive, computationally speaking. You're absolutely right. It is. The compute costs just to train these huge AI models, they're really high and they keep going up. But, and this is key, the costs for inference, the cost per unit of actually using the trained model, like per word generated, those costs are falling, quite significantly actually. Huh, so it's super expensive to build the brain, but it's getting cheaper each time you ask it to think, basically. That's a pretty good analogy, yeah. And this creates this really powerful flywheel effect. See, lower per unit inference costs make AI cheaper for everyone to use day to day. That naturally fuels way higher overall usage. But then that increased usage drives up the total demand for all the underlying infrastructure. The servers, the power, the chips, which pushes the overall costs and investment needed higher again. It just feeds itself. And that massive demand translates into huge capital investment, right? We must be seeing billions flowing into this. Oh, absolutely. Tech companies are just pouring money into R&D. The big six US tech firms, they're now spending something like 13% of their revenue on R&D. That's up from 9% just a decade ago. And their capital expenditures, you know, CapEx across the big cloud providers, it's scaling dramatically just to build out all the hardware needed. And data centers seem to be right at the heart of that physical buildout. They really are the literal engine rooms for these AI models. The sources highlight some pretty stark numbers. USA data center private construction value is climbing significantly, up 28% per year. And the amount of space being absorbed or currently under construction, up an incredible 49% per year. To put it another way, new data center construction increased 16 times compared to existing capacity only growing five times over just four years, from 2020 to 2024. Wow. And I think one source called them electricity guzzlers, which definitely gives you a sense of the energy footprint involved here. Yeah, it really highlights a critical constraint, doesn't it? And a major implication of scaling this fast. And of course, enabling all of this are the chips themselves. Right. NVIDIA. That's the name everyone seems to know in this space. And their numbers reflect that demand perfectly. The sources show just massive growth, like 78% year-over-year increase, leading to $39 billion in quarterly revenue. And something like 28x growth over the last 10 years. It's huge. But it's not just NVIDIA

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
