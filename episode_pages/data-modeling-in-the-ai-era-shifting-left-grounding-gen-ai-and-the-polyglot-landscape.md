# Data Modeling in the AI Era: Shifting Left, Grounding Gen AI, and the Polyglot Landscape

**Published:** May 12, 2025  
**Duration:** 15m 59s  
**Episode ID:** 17692130

ðŸŽ§ **[Listen to this episode](https://intellectuallycurious.buzzsprout.com/2529712/episodes/17692130-data-modeling-in-the-ai-era-shifting-left-grounding-gen-ai-and-the-polyglot-landscape)**

## Description

We cut through the hype around AI to explain why solid data modeling is the bedrock of reliable AI today. This episode covers shifting data quality into the operational layer, the difference between AI in analytics versus realâ€‘time ops, grounding LLMs with structured context, retrieval + graphs, knowledge graphs, and the rise of AI agents in a polyglot data world.

## Transcript

Welcome to The Deep Dive. We try to cut through the noise on complex computer science and software engineering topics to get you the core insights quickly. Today, we're looking at something absolutely fundamental to AI data modeling. Right. Maybe not the flashiest part of AI, but arguably one of the most critical. Exactly. And there's this tempting idea floating around that maybe, just maybe, these super smart AIs can just figure out messy data, you know, clean it up themselves. Yeah, that's a common hope, I think. But the source we're looking at today, an article from The New Stack, really pushes back on that. It does. It's called AI Won't Save You From Your Data Modeling Problems. Pretty direct title. Very direct. And it argues that actually, good data modeling is more vital now in the age of AI than it ever was before. So our mission here is to dig into that. Why is solid data modeling the bedrock for AI, especially now? Let's unpack it. Sounds good. The article points out that historically, data quality was often seen as, well, an analytics problem, something you'd fix later. Right. You collect all the data, dump it in a data warehouse or a lake, and then someone else downstream cleans it up. Exactly. The data teams would handle the cleaning, the prep, getting it ready for reports or maybe traditional ML models. But that whole approach seems fundamentally at odds with how modern AI, especially generative AI, works, doesn't it? It really is. Gene AI operates in real time. It's making decisions, generating content, interacting dynamically. It doesn't wait for a batch cleanup process. So if the data it's getting right now is bad, what happens? Well, the AI doesn't magically fix it. It just uses the bad data. It makes flawed decisions or generates incorrect information, but, you know, really fast. Not exactly an improvement. Not at all. The article uses this great analogy. It's like driving a car but only getting to see the road clearly for a second every five minutes. Yeah, you're headed for disaster. Pretty much guaranteed. So the consequence is bad AI outputs, unreliable behavior. Okay, so the old way is out. The article proposes this idea of shifting left with data modeling. What does that mean in practice? Shifting left is about tackling data quality much earlier in the process. Instead of fixing it downstream in the analytics phase... You fix it closer to the source. Exactly. You build the quality checks and the modeling structure into the operational layer where the applications create and use the data in the first place. Ah, so it's about prevention rather than cure, basically. Building quality in from the start. That feels very aligned with good software engineering principles. It absolutely is. Make the data right before it even gets to the AI. The article then makes an important distinction talking about AI in the operational world versus the analytics world. Can you break that down? Sure. The traditional AI analytics pipeline, as we said, was collect, aggregate, clean, train, predict. That works fine for looking back for analysis. Business intelligence, understanding trends, that kind of thing. Right. But Gen AI often flips that. The models themselves might be pre-built, pre-trained on vast data sets. Their real power comes from feeding them fresh, specific context at runtime. Context about my business, my data, right now. Precisely. And where does that live? It lives in the operational systems, the applications running the business day to day, not primarily in the data warehouse, which is often aggregated and slightly delayed. So trying to shoehorn real-time AI into that old analytics stack is problematic. Yeah, the article argues it really is. Aggregation is too slow. And trying to push corrected data back from the warehouse into operational systems, reverse ETL, that tends to be brittle, complex, and you often end up with stale data anyway. Okay, give us an example. Think about a Gen AI flight assistant like the article mentions. You want it to help you rebook a canceled flight. It needs real-time info. Like which flights have seats available right this second? Exactly. And maybe the layout of the plane, your seating preferences, your frequent flyer status. That information isn't sitting neatly aggregated in a data warehouse from last night's batch run. It's live in the airline's reservation system. Got it. The operational layer is key for that immediate context. Absolutely crucial. Which leads us to the next point. Data models aren't just for BI anymore. Historically, we built models mainly to structure data for, you know, dashboards and reports. Right. Star schemas, snowflake schemas, all aimed at making reporting easier and faster. But AI changes the game. It pushes that responsibility for well-structured data much earlier into that operational layer because the AI needs it for decisions, not just reports. And the article talks about foundation models being incredibly intelligent but also kind of dumb. Hey, yeah, that's a good way to put it. They have immense general knowledge from their training data, but they know nothing specific about your customers, your products, your processes. They need that context fed to them. And they need it in a way they can understand. That means structured data, maybe unstructured text too, but critically, data that's defined and related correctly. Without that well-modeled context, the article warns, you get... Hallucinations. It's plausible-sounding nonsense. Exactly. Unreliable outputs because the AI is essentially guessing based on incomplete or misunderstood information. Okay, let's talk retrieval augmented generation, R-TRED. That's a huge topic right now. The common view is it's mostly about semantic search over, like, documents, right? Vector databases. That's definitely a big part of it, yeah. Vectorizing unstructured text and finding semantically similar chunks is key. But the article says that's often not enough in the real world. Right. For many practical uses, you need a hybrid approach. You need the semantic search, but you also need to pull precise, structured information from traditional databases, CRMs, ERP systems. Things like, what's this customer's actual order history? Or how many units of this specific product are in stock right now? Precisely. Semantic search alone might pull up documents that mention inventory or orders, but it might not give you the exact, current, accurate number you need for a specific task. It can be relevant, but wrong. And even if you're mostly using semantic search, a good data model still helps. How? Absolutely. Because a well-defined data model, one that clearly lays out your key business entities, like customers, products, orders, and how they relate, acts as a kind of validation layer. Ah, so the LLM generates an answer based on retrieved documents, and you can check if that answer makes sense according to the rules defined in your structured data model. Exactly. It helps ground the potentially fuzzy output of the LLM in the concrete reality defined by your business rules and data structures. The article brings up knowledge graphs here. How do they fit in? A knowledge graph is really a specialized form of a conceptual data model. It focuses explicitly on capturing entities and their relationships within a domain in a structured graph format. Like the TrackMeet example they gave. Athletes, events, attendees. Yeah, that's a great simple example. Without a clear model defining what an athlete is, what an event is, and how they relate, peachy athlete participates in event, you could have inconsistencies. The knowledge graph provides that standardized, unambiguous structure. And this leads to things like graph reg. Right. Graph reg uses the knowledge graph structure directly to guide the information retrieval for the LLM, often leading to much more accurate and contextually relevant answers. Microsoft Research, mentioned in the article, showed significant improvements using this approach. So the model helps ensure the AI's insights align with how the business actually defines things. Precisely. It's a cross-check against your structured business reality. Okay, shifting gears slightly from R-REG to AI agents. What's the distinction? And why are data models, according to the article, even more critical here? AI agents go a step beyond just retrieving and synthesizing information like R-REG does. Agents can actually take actions. They can query systems, sure, but they can also potentially update data or trigger processes in operational systems. Okay, that sounds powerful, but also potentially risky if not managed carefully. Extremely risky. For an agent to act reliably and safely, it must have a clear, structured understanding of its environment. That means a robust data model defining the entities it can interact with, the relationships between them, and crucially, the rules governing its actions. Like, what data can it change? Under what conditions? What are the valid states or values? All of that. Think of an AI agent handling customer support. It might need to look up an order, but it might also need permission to update a shipping address. The data model defines what's possible and what's allowed based on business rules. So the article lists benefits like validating agent outputs, understanding data relationships in real time, enabling interoperability. Yeah, all stemming from that core need for structure. Without the model, the agent is operating blind, potentially making errors, violating business logic, or failing to coordinate with other systems. The data model is its map and its rulebook. It's the agent's source of truth for how its world works. Couldn't have said it better myself. Now, the data landscape today isn't just neat relational tables anymore, is it? The article introduces polyglot data modeling. What's that about? Right. Traditional modeling often focused heavily on relational databases like SQL and entity relationship diagrams. But modern systems use everything. JSON documents, graph databases, APIs, streaming data, key value stores, a whole mix. A polyglot environment, meaning many languages or types of data. Exactly. Polyglot data modeling is an approach that acknowledges this diversity. It aims to create a unified model that can represent and manage relationships across these different kinds of data sources

---
*This episode was generated from the Intellectually Curious Podcast. For more episodes, visit our [main site](https://intellectuallycurious.buzzsprout.com).*
